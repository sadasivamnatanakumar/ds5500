 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu.  of two variables, or several variables. And now we try to study more in detail how functions of several variables behave, how to compute their variations, how to estimate the variation in arbitrary directions. And so far, we're going to need some more tools, actually, to study these things. So, more tools to study,  functions. And so, today's topic is going to be differentials. And just to motivate that, let me  And I will remind you about one trick that you probably know from single-viable calculus, namely implicit differentiation. So let's say that you have a function y equals f of x.  d y equals f prime of x times d x. And then, maybe you would, excuse me, can you please take a seat and, you please take a seat and sit down. That would be better. Thank you. So we use implicit differentiation to actually relate infinitely symbol to the fact  changes in y, with infinitesimal changes in x. And one thing we can do with that, for example, is actually figure out the rate of change dy by dx, but also the reciprocal dx by dy. And so, for example, let's say that we have y equals inverse sign of x.  x equals sine of y, and from there we can actually find out what is the derivative of this function. If we didn't know the answer already, by writing d x equals cosine y d y. And so that tells us that d y over d x is going to be one of our cosine y.  the real line for relation to sine is basically one of our square root of 1 minus x  but use them for functions of several variables. And, of course, we'll have to learn what are the rules of manipulation and what we can do with them. So, the actual name of that is the total differential, as opposed to the partial derivatives, because, well, it's going to be the total differential, because it includes all of the various causes that can change,  sorry, all of the contributions that can cause the value of your function f to change. So namely, let's say that you have a function f, maybe of three variables x, y, z, then you will write d f equals f sub x d x plus f sub y d y plus f sub z d z. OK, or maybe I'll write it out in the following.  just to remind you of the other notation, partial f, partial x dx plus partial f, partial y dy plus partial f of partial z dz. Now, what is this object? What are the things on either side of this equality? Well, they're called differentials. And there are not numbers. There are not vectors. There are not matrices. There are a different kind of object.  So, this things have their own roles of manipulations, and we have to learn what we can do with them. So, how do we think about them? So, first of all, how do we not think about them? OK, so here's an important thing to pitfall to avoid.  f is not the same thing as delta f. So that thing is meant to be a number. It's going to be a number once you have a small variation of x, a small variation of y, a small variation of z. These are numbers. delta x delta with delta z are actual numbers. And this becomes a number. This guy actually is not a number.  all you can do with a differential is express it in terms of other differentials. So, in fact, this dx, dy and dz, well, they're mostly symbols out there, but if you want to think about them, there are the differentials of x, y and z. So, in fact, you can think of these differentials as placeholders, where you will put other things. So, of course, they're represented, you know, there's this idea of changes in x, y is E and f.  but so one way that one could explain it, I don't really like that, is to say they represent infinitesimal changes. Another way to say it, and I think that's probably closer to the truth, is that these things are somehow placeholders to put values and get a tangent approximation. So for example, if I do replace these symbols by delta x, delta y, and delta z numbers,  we'll actually get a numerical quantity, and that will be an approximation formula for delta if. It will be the linear approximation of the tension play in approximation. So what we can do, well, so let me start first with, maybe something even before that. So the first thing that it does is it can encode how  So, the change is in xyz, a fact, the value of f. I would say that's the most general answer to what is this formula, what are these differentials. It's a relation between xyz and f. And in particular, so this is a place holder.  for small variations, delta x, delta y, delta z, to get an approximation formula, which is delta f is approximately equal to f sub x, delta x, plus f y,  delta y plus fz, delta z. Sorry, it's getting cramped, but I'm sure you know what's going here. So, and observe how this one is actually equal, while that one is approximately equal. So, they're really not the same. Another thing that the notation suggests we can do, and I claim we can do, is divide everything by some variable that everybody depends on. So, say, for example,  that x, y, and z actually depend on some parameter, t. Then they will vary at a certain rate, dx, dt, dz, dt. And what the differential will tell us then is the rate of change of f as a function of t when you plug in this values of x, y, z. You will get df dt by dividing everything by dt in here.  OK, so the first thing we can do is divide by, say, something like dt, to get an infinitesimal rate of change, by instance,  let me just take a rate of change. OK, so dF dt equals f sub x dX dt plus f sub y dY dt, plus f sub z dz dt. And that corresponds to the situation  where x is a function of t, y is a function of t, and z is a function of t, then that means you can plug in these values into f, to get, well, the value of f will depend on t, and then you can find the rate of change with t of a value of f. So these are the basic rules.  And this is known as the chain rule. It's one instance of the chain rule, which tells you when you have a function that depends on something and that something, in turn, depends on something else, how to find the rate of change of a function on the new variable in terms of the derivatives of a function, and also the dependence between the various variables.  OK, any questions so far? No? OK, so a word of warning, in particular, about what I said up here, it's kind of unfortunate, but the textbook actually has a serious mistake on that. I mean, they do have a couple of formulas where they mix a d with the delta, and I would like you not to do that, please.  And in this d's and d's delta's, and basically, they don't live in the same world. They don't see each other. The textbook is lying to you. OK, so let's see.  really need to justify it, because the first one is just stating some general principle, but I'm not making a precise mathematical claim. The second one, well, I mean, we know that approximation formula already. So I don't need to justify it for you. But on the other hand, this formula here, I mean, you probably have your right to expect some reason for why this works. Why is this valid? After all, I first told you we have this new mysterious object, and then I'm telling you,  well, we can do that, which I kind of pulled it out of my hat. I mean, I don't have a hat, but. OK, so why is this valid? How can I get to this? So here's a first attempt at justifying how to get there.  So let's see. Well, we say df is f sub x dx plus f sub y dy plus f sub z dz.  d y is y prime of t dt. dz is z prime of t dt. So if we plug these into that formula, we'll get that df is f of x times x prime of dt plus f of y prime of dt.  of t dt plus f sub z, z prime of t dt. And now, well, if I have a relation between df and dt, see, I got df equals something times dt. That means the rate of change of f with respect to t should be that coefficient. So if I divide by dt,  then I get the formula that's, well, I get the chain hole. Now, well, that kind of works, but that shouldn't be completely satisfactory.  natural notations in deriving the answer. So that's actually not how it's proved, the way in which you prove the chainhole, is not this way. We shouldn't have too much trust in differentials addressed yet. At the end of today's lecture, yes, probably we should believe in them, but so far we should still be a little bit reluctant to believe this kind of strange object telling us weird things.  Here's a better way to think about it. So one thing that we have trust in so far, our approximation formulums, is we should have trust in them. So we should believe that if we change x a little bit, if we change y a little bit,  then we are actually going to get a change in f that's approximately given by these guys. So now, well, this is true for any changes in x, y, z. But in particular, let's look at the changes that we get if we just take these formulas as functions of time and change time a little bit by delta t. OK, so we'll actually use the change in f  And this change is in x yz in a small time delta T. And let's divide everybody by delta T. OK, here I'm just dividing numbers. So I'm not actually playing in the tricks on you. I mean, we don't really know what it means to divide the French roles, but dividing numbers is something we know.  if I take delta t very small, then this guy tends to the different role. Sorry, it tends to the derivative, df dt. Remember, the definition of df dt is the limit of this ratio when the time interval delta t tends to 0. So that means if I get, you know, if I choose smaller and smaller values of delta t,  then these ratios of numbers will actually tend to some value, and that value is the derivative. So similarly, here, delta x over delta t, when delta is really small, will tend to the derivative, dx dt.  So, so if we take the limit as delta t tends to 0,  f dt, on one side, on the other side we get f sub x d x dt plus f sub y d y dt plus f of z d z dt. And the approximation becomes better and better. Remember when we write approximately equal, that means that it's not quite the same, but if we take smaller and smaller variations, then actually we'll end up with values that are  are getting closer and closer. So, when we take the limit, as delta turns to 0, eventually we get an equality. I mean, mathematicians have more complicated words to justify this statement, but I will spare them for now, and you will see about them when you take analysis.  if you go on in that direction. Any questions so far? No. OK, so let's check maybe things in an example. Let's say that we really don't have any faith in these things. And so let's try to do it.  So, let's say I give you a function that's x squared y plus z. And let's say that maybe x will be t, y will be e to the t, and z will be sine t.  So, what does the chainhold say? Well, the chainhold tells us that dw dt is, so we start with partial w, or partial x. Well, what is that? That's 2xy times, so maybe I should point out this is w sub x.  x times dx dt plus, well, w sub y is x squared times dy dt plus w sub z.  in the actual values of these things. So x is T, y is e to the T. So it will be 2t e to the T. d x dt is 1 plus x squared is T squared. d y dt is e to the T. Plus d dt is cosine T.  the end of calculation we get 2t e to the t plus t square e to the t plus cosine  And in fact, in this case, the two calculations are, hopefully, equal and complication. But say that your function of x, y, z was much more complicated than that, or maybe you actually didn't know a formula for it. You only knew its partial derivatives, then you would need to use the chain rule. So sometimes plugging in values is easier, but not always.  So, let's just check quickly. So, the other method would be to substitute. So, w as a function of t, well, so remember, w was, was it x squared y  So as a function of t, well, x was t, so you get t squared, y is e to the t, plus 0 is sine t. So dw dt, we know how to take the derivative using single variable calculus. Well, we should know, if we don't know then we should take a look at 18.01 again. So by the product whole, that will be derivative of t squared is 2t times e to the 1 over c.  the t plus c squared times the derivative of e to the t is e to the t, plus cosine t. And that's the same answer as over there. So I ended up writing up, maybe I would slightly more here, but actually the amount of calculations really was pretty much the same.  OK, any questions about that? Yes? What kind of object is W? So, well, I was intending, you can think of W as just another variable that's given as a function of x, y and z, for example. So, you'll have a function of x, y, z defined by this formula. And I call it W. I call it's value, W, so that's then I can substitute, instead of x, y, z.  So, w is, well, let's think of w as a function of three variables. OK, and then when I plug in the dependence of these three variables on t, then it becomes just a function of t. I mean, really, my w here is pretty much what I called f before. There's no, you know, there's no major difference between the two.  OK, any other questions? So let's see. Here's an application of what we've seen. So let's say that you want to understand, actually, all of these  how to take the derivative of your reciprocal function. And for that, you didn't need multiviable calculus. But let's try to justify the product hold, for example, for the derivative. So an application of this, actually, is to justify the product and quotient holds.  So let's think, for example, of a function of two variables, u and V, that's just the product, u, V. OK? And let's say that u and V are actually functions of one variable, T. Then, well, d by dt, df dt, so let's say d of u, V over dt, is given by the chain role.  apply to f. This is df dt. So df dt should be f sub u dudt plus f sub v times dv dt. Right? But now, what is the partial of f with respect to you? It's v. So that's v dudt. And partial of f with respect to v is going to be,  just you. So, you get back the usual product, OK? That's a slightly complicated way of deriving it, but that's a valid way of understanding how to take the derivative of the product by thinking of the product, first as a function of two variables, which are u and v, and then saying,  x is a variable T, and then you do the  c, then well, dg dt is going to be partial g, powerful u, how much is that? How much is partial g, one over V, times dudt, plus, well, next we need to have partial g of a powerful v,  well, what's the derivative of this with respect to V? Well, here we need to know how to differentiate the inverse. It's minus U over V squared times Vv dt. OK? And that's actually the usual proof and whole, just written in a slightly different way. I mean, just in case you really want to see it,  If you clear the denominators to put the V-squared, then you will see, basically, V, well, you find times V minus V prime times U.  OK, now let's go to something even more.  it's like even more crazy, I claim we can do chain rules with more variables. So let's say that I have a quantity, let's call it W today for now. So let's say I have quantity W as a function of, say, two variables x and y.  dependent on some parameter t. But actually, let's now look at the case where x and y, themselves, are functions of several variables. Let's say of two more variables. Let's call them u and v. OK, so I'm going to stay with these abstract letters. But if it bothers you, if it sounds completely unmotivated,  And think about it maybe in terms of something you might know, say, polar coordinates. Let's say that I have a function that's defined in terms of the polar coordinate variables R and theta. And then I know actually I want to switch through usual coordinates x and y. Now, we have our way around. I have a function of x and y. And I want to express it in terms of the polar coordinates R and theta. Then I would like to know maybe how the derivatives, with respect to the various set of elements,  variables are related to each other. So, one way I could do it is, of course, to say, well, now if I plug the formula for x and the formula for y into the formula for f, then w becomes a function of u and v, and I can try to take its partial derivatives. If I have explicit formulas, well, that could work.  but maybe the formulas are complicated. Typically, if I switch between rectangular and polar coordinates, there might be inverse trig, there might be maybe Arc tangent to express the polar angle in terms of x and y. And then I don't really want to actually substitute Arc tangents everywhere. Maybe I'd rather deal with the derivatives. So how do I do that?  So the question is what are partial W of partial U, and partial W of partial V, in terms of, so let's see, what do we need to know, now to understand that? Well, probably we should know how W depends on x and y.  x, partial W, partial x, partial W, partial y, should be required. What else should we know? Well, it would probably help to know how x and y depend on u and v. If we don't know that, then we don't really know how to do it either. So we need also, well, use of x, sorry, over around, x sub u, x sub v, y sub v.  well, so let's see how we can do that. So let's start by writing dw. So we know that dw is partial f, well, I don't know why I have two names, w and f. I mean, w and f are really the same thing here, but let's say f sub x dx plus f sub y dy.  So far, that's our new friend, the differential. Now, what do we want to do with it? Well, we'd like to get rid of dx and dy, because we'd like to express things in terms of, you know, the question we are asking ourselves is, let's say that I change you a little bit. How does w change? So, of course, what will happen is if I change you a little bit, then x and y will change.  how do they change? Well, that's given to me by the differential. So d x is going to be, well, I can use the differential. Again, d x, well, x is a function of Q and V, that will be x sub U times d U plus x sub V times d V. That's, again, taking the differential of a function  function of two variables. Does that make sense? Then we have the other guy, f sub y, times what is dy? Well, similarly, dy is y sub u d u plus y sub v dv. And now we have a relation between dw and dv. We are expressing how w reacts to change in u and v.  which was our goal. Now, let's actually collect terms, so that we see it a bit better. So that's going to be f sub x times x sub u plus f sub y times y sub u d u plus f sub x x sub v plus f sub y y sub v d v.  So now we have dw equals something du plus something dv. Well, that coefficient here has to be partial f partial u. What else could it be? Right? That's the rate of change of w with respect to u if I forget what happens when I change v. That's the definition of the partial. Similarly, this one has to be partial f of partial v.  xn is C, that's because it's the rate of change with respect to V if I keep you constant, so that these guys are completely ignored. OK, so now you see how the total differential accounts for somehow all the partial derivatives that come as coefficients of the individual variables in these expressions. OK, so let me maybe rewrite this  in a visible way, and then we explain them to you. OK, so here's the chain rule for this situation, with two intermediate variables and two variables that you express these in terms of. So, in our setting, we get partial f of a partial u equals partial f of a partial x, partial x of a partial  partial f of the partial y times partial y of the partial use. And the other one, same thing with V instead of you, partial f partial x times partial x partial V plus partial f partial y partial y partial V. So I have to explain various things about this formula.  because they look complicated, and actually, they're not that complicated. So, a couple of things to know. First thing, so how do we remember our formula like that? Well, that's easy. We want to know how f depends on you. Well, what does f depend on, actually? It depends on x and y. So, we'll put partial f partial x and partial f partial y. Now, x and y, y are there here, because they're  actually depend on you as well. x depend on you, well, the answer is partial x partial to you. So see, the structure of this formula is simple to find the partial of f with respect to some new variable. You use the partial with respect to the variables that f was initially defined in terms of x and y, and you multiply them by the partial of x and y in terms of the new variables.  variable that you want to look at, V here, and you sum these things together. OK, so that's the structure of the formula. Why does it work? Well, let me explain it to you in a slightly different language. So this asks us, how does f change if I change you a little bit? OK, well, why would f change if you change this a little bit? Well, it would change because f actually depends on x and y, and x and y depend on you.  If I change you, how quickly does x change?  epsilon f are for y, so the product is the effect of how you change it, changing y, and therefore changing f. Now, what happens in real life if I change you a little bit? Well, both x and y change at the same time. So, how does f change? Well, it's the sum of the two effects. OK, does that make sense? Good. Of course, if f depends on more variables than you just have more terms in here.  OK, here's another thing that may be a little bit confusing. So what is tempting? Well, what's tempting here would be to simplify this formulose by removing this partial x's. So let's simplify by partial x. Let's simplify by partial y. We get partial f partial u equals partial f partial u plus partial f partial u. Something is not working properly. OK, so why doesn't it work?  these are not total derivatives. And so you cannot simplify them in that way. And that's actually the reason why we use this curly d rather than a straight d. It's two reminders, beware, there's these simplifications that we can do with straight d's that are not legal here. So somehow, when you have a partial derivative, you must resist the urge of simplifying things. OK, so no simplifications in here.  OK, any questions at this point? Nope. Yes? So, when would you use this? And what does it describe? Well, it's basically when you have a function given in terms of a certain set of variables, because maybe there's a simple  expression in terms of those variables, but ultimately what you care about is not those variables x and y, but another set of variables here, u and v. So x and y are giving you a nice formula for f, but actually the relevant variables for your problem are u and v. And you know how x and y are related to u and v. So, of course, what you could do is you could plug the formulas, the way that we did substituting, but maybe that will give you very complicated expressions. And maybe it's actually easier to just work with the derivative  So the important claim here is basically we don't need to know the actual formulas, or we need to know if the rate of changes. If we know all of these rates of change, then we know how to take these derivatives without actually having to plug n values. Yes? Yes, you could certainly do the same things in terms of t if x and y were functions of t, instead of being functions of q and v,  then it would be the same thing. And you would have the same formulose that I had, well, over there I still have it. So why does that one have straight ds? Well, the answer is I could put curly ds if I wanted, but I end up with a function of a single variable. So if you have a single variable, then the partial with respect to that variable is the same thing as the usual derivative. So we don't actually need to worry about curly in that case. OK, but that one is, indeed, it's a special case of this one, where, instead of x and y depending on the function,  two variables, you and V, they depend on a single variable, T. Now, of course, whether you call your  OK, any other questions? No? Yes, what? Oh, yes.  So if you and V depended on yet another variable, then you could get the derivative with respect to that using first the chain rule to pass from UV to that new variable. And then you would plug in these formulas for the partial of f respect to you and V. So in fact, if you have several substitutions to do, you can always arrange to use one chain rule at the time. You just have to do them in sequence. So that's why we don't actually learn that. But you can just do it by repeating the process.  And probably at that stage, the easiest to not get confused, actually, is to manipulate differentials, because that's probably easier. So, curly f does not exist. That's easy. Curly f makes no sense. By itself, it doesn't exist alone. What exists is only curly f over curly d, some variable.  for the rate of change with respect to that variable, leaving the others fixed, while straight df is somehow a total variation of f. And so it accounts for all of the partial derivatives and their combined effects. OK. Any more questions? Nope. OK, so let me just finish very quickly by telling you again,  So, one example, where concretely you might want to do this, is you have a function that you want to switch between rectangular and polar coordinates. So, just to make things a little bit more concrete, so if you have polar coordinates, that means that in the plane, instead of using coordinates x and y, you will use coordinates x and y.  are in distance to the origin and the f of the angle from the x-axis. So the change of variables for that is x equals R cosine theta and y equals R sine theta. And so that means, well, if you have a function f that depends on x and y, then in fact you can plug this and get a function of R and theta. And then you can ask yourself,  well, what is partial f of a partial R? And that's going to be, well, you want to take partial f, partial x, partial x, partial R, plus partial f, partial y, partial R. And so that will end up being actually f sub x times cosine theta, plus f sub y times sine theta.  and do the same thing to find partial f, partial f, atheta. So you can express derivatives either in terms of xy or in terms of R and fader, with simple relations between them. And the, oh, yes, and one last thing I should say. So on Thursday, we'll learn about more tricks we can play with variations of functions, and one that's important because you need to know it actually to do the p-set,  So the gradient vector, it's simply a vector, so you use this downward-paunting triangle, as a notation, for the gradient.  way to package powerfuls together. So we'll see on Thursday what it's good for, that some of the problems on the Pset use it.
 The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. Today, we're going to see how to use what we saw last time about partial derivatives.  to handle minimization or maximization problems, involving functions of several variables. So, we found that. So, remember, last time we say it, but when we have a function, say, of two variables, x and y, then we have, actually, two different derivatives. Partial f, partial x, also called f sub x, is the derivative with respect to x, keeping y constant.  x. And we have partial f partial y, also called f of y, where we vary y and we take x as a constant.  I'm not in a recitation yesterday, is the approximation formula that tells you what happens if you value both x and y. So f sub x tells us what happens if we change x a little bit by some small-mount delta x. f sub y tells us how f changes if we change y by a small-mount delta y. If we do both at the same time, then the two effects will add up with each of our questions.  well, because you can imagine that first you will change x, and then you will change y over the other way around. It doesn't really matter. So if we change x by a certain amount, delta x. And if we change y by the amount delta y, and let's say that we have z equals f of xy, then we have x minus x is less than x.  And that changes by an amount, which is, approximately, f sub x times delta x, plus f sub y times delta y. OK, and that's one of the most important formulas about partial derivatives. OK, so the intuition for this, again, is just the two effects add up.  will modify f, how much does it modify f? The answer is the rate of change is f sub x. And if I change y, then the rate of change of f, when I change y, is f sub y. So all together, I get this change in the value of f. And, of course, that's only an approximation for Mura. Actually, there would be higher order terms involving second and third derivatives and so on. So, one way to justify this,  So I was distracted by my call for the problem. OK, so how do we justify this formula?  So let's think about the tangent plane to the graph of the function f. OK, so I have some pictures to show you.  the graph of f by a plane, that's parallel to the x is a plane. And then, when I change x, z changes, and the slope of that is going to be the derivative respect to x. So now, if I do the same in the other direction, then I will have similarly the slope in a slice now parallel to the y is a plane that will be partial f partial y. So, in fact, in each case, I have a large  And that line is tangent to the surface. So now if I have two lines, tangent to the surface, well, then, together, they determine for me the tangent plane to the surface. OK, so let's try to see how that works. We know that f sub x and f sub y are slopes of two tangent lines.  to this plane, sorry, two tensioned lines, to the graph. And let's write down the equations of these lines. I'm not going to write parametric equations. I'm going to write them in terms of x, y, z coordinates. So let's say that partial f of our partial x at a given point is equal to a. Then that means that we have a line given by the following.  conditions, so I'm going to keep y constant equal to y0, and I'm going to change x. And as I change x, z will change at your right that's equal to a. So that would be z equals z0 plus a times the change in x, x minus x is 0. OK, that is how you would describe the line that's, I guess, the one that's plotted in green here,  that's the intersection with a slice parallel to the x is a plane. I hold y constant equal to y0. And z is a function of x that varies with the rate of a. OK? And now, if I look similar at the other slice, let's say that the partial with respect to y is equal to b, then I get another line, which is obtained by the real number  x is a very simple way to show that the fact that z now will depend on y and the rate of change with respect to y will be b, while x is held constant equal to x is 0.  So, they are both tangential to the 1-th of f. And, well, together, they come in a plane.  x minus x0 plus b times y minus y0. If you look at what happens, so this is the equation of a plane, z equals constant times x plus constant times y plus constant. And if you look at what happens if I hold y constant and vary x, I require the first line, if I hold x constant and vary x, I require the first line,  and then there are y, I get the second one. Another way to do it, of course, would be to write actually parametrix equations of these lines, get vectors along them and then take the cross product to get the normal vector to the plane and then get this equation for the plane using the normal vector. That also works and it gives you the same formula. So, if you are curious, exercise, do it again using parametrix and using cross product to get the plane equation.  So that is how we get the tangent plane. And now what this approximation formula here says is that, in fact, the graph of the function is close to the tangent plane. If we were moving on the tangent plane, this would be an actual equality. Delta z would be a linear function of delta x and delta y. And the graph of the function is near the tangent plane, but it is not quite the same. So it is only an approximation for small delta x and small delta y.  So the approximation formula says the graph of f is closed to its tangent plane.  now, to estimate how the value of f changes if I change x and y at the same time. OK, questions about that? OK, so now that we've caught up with what we were supposed to see on Tuesday, I can tell you now about max and min problems.  So that's going to be an application of partial derivatives.  So maybe, you know, 10 years from now, when you have a real job, your job might be to actually minimize the cost of something or maximize the profit of something, or whatever. But typically, the function that you will have to, you know, strive to minimize or maximize will depend on several variables. So if you have a function of one variable, you know that to find its minimum or its maximum, you look at the derivative, and you set that equal to 0, and you try to then look at what happens,  function. So here it is going to be kind of similar, except of course we have several derivatives. So for today we will think about a function of two variables, but it works exactly the same if you have three variables, 10 variables, a million variables.  So, the first observation is that if we have a local minimum or a local maximum, then both partial derivative, so partial f partial x and partial f partial y, are both 0 at the same time.  x is 0, that means when I vary x, well, to first order, the function doesn't change. Maybe that's because it's going through. If I look only at the slice parallel to the x-axis, then maybe I'm going through the minimum. But then if partial f partial y is not 0, then actually, by changing y, I could still make a value larger or smaller. So that wouldn't be an actual maximum or minimum.  I draw myself to change y that doesn't work. So I need actually to know that if I change y, the value will not change either to first order. So that's why I also need partial f partial y to be 0. Now, let's say that we are both 0. Well, why is that enough? It's essentially enough because of this formula telling me that if both of these guys are 0, then to first order, the function doesn't change. And then, of course, there will be maybe quadratic terms that will actually turn that, you know, this won't really  say that your function is actually constant, it will just tell you that maybe it will be actually quadratic or higher order in delta x and delta y. That's what you expect to have at a maximum or a minimum. So we have, so that condition is the same thing as saying that the tangent plane,  to the graph, is actually going to be horizontal. OK, and that's what you want to have. Say you have a minimum, well, see that the tension plane at this point, at the bottom of the graph, is going to be horizontal.  And you can see that on this equation of the tangent plane, when both these coefficients are 0, that's when the equation becomes z equals constant, the horizontal plane. OK, does that make sense? OK, so we'll have a name for this kind of point, because actually, what we'll see very soon is that these conditions are necessary, but they are not sufficient.  the partial derivatives are 0. So let's give a name to this. We say the definition we say that x, let's say x 0, y 0, is a critical point of f.  So the partial derivatives with respect to x, and the partial derivative with respect to y, are both 0. OK? Not only you would want all the partial derivatives, no matter how many variables you have, you want all the partials to be 0 at the same time. OK?  So let's say I give you the function f of xy equals x squared minus 2xy plus AY squared plus 2x minus 2y.  maximize this. Well, so what we start doing immediately is taking the partial derivatives. OK, so what is f sub x? It starts with 2x minus 2y plus 0 plus 2. OK, remember that y is a constant, so this differentiates to 0.  x, that's going to be, well, 0 minus 2x plus 6y minus 2. And what we want to do is set these things equal to 0. And we want to solve these two equations at the same time. OK, so an important thing to remember. I mean, maybe I should have told you a couple of weeks ago already. If you have two equations to solve, well, it's very good to try to simplify them by adding them together or whatever.  but you must keep two equations. If you have two equations, you should not end up with just one equation out of nowhere. So, for example, here we can certainly simplify things by summing them together. See, if we add them together, while the x is cancelled and the constants cancel, and in fact, we're just left with 4y equals 0, that's pretty good.  but then we should, of course, go back to these and see what else we know. Well, now it tells us, so if you put y equals 0, it tells you 2x plus 2 equals 0. And that tells you x equals minus 1. OK, so we have one critical point. That's xy equals minus 1 and 0.  OK? Any questions so far? No? Well, you should have a question. Questions should be, how do we know if it's a maximum or a minimum? Well, yeah, so if we had a function of one variable, we would decide things based on the second derivative. And in fact, we'll see tomorrow how to do this.  things based on the second derivative, but that's kind of tricky because there's a lot of second derivatives. We already have two first derivatives. You can imagine that if you keep taking partials, you may end up with more and more. So we'll have to figure out carefully what the condition should be. So we'll do that tomorrow. For now, let's just try to look a bit at how do we understand these things by hand.  So, in fact, let me point out to you immediately that there's more than max x m n minima. So, remember, we saw the example of x squared plus y squared that has a critical point. That critical point is, obviously, a minimum. And, of course, it could be a local minimum because it could be that, you know, if you have a more complicated number,  function, there's, indeed, a minimum here, but then elsewhere, the function drops to a lower value. So we call that just a local minimum to say that it's a minimum if you stick two values that are close enough to that point. Of course, you also have a local maximum, well, I didn't plot it, but it's easy to plot. OK? That's a local maximum. But there's a third example of critical point, and that's a saddle point.  So for a saddle point, it's a new phenomenon that you don't really see in the single variable calculus. It's a critical point that's neither a minimum nor a maximum, because depending on which direction you look in, it's either one or the other. So here, see, the point in the middle at the origin is a saddle point. If you look at the tangent plane to this graph, you'll see that it's actually horizontal at the origin.  you have this mountain pass, the round is horizontal. But depending on in which direction you go, you go up or down. So we say that the point is a saddle point if it's neither a minimum nor a maximum.  So, possibility this could be a local min, a local max, or a set. OK, so, tomorrow we'll see how to decide which one it is, in general, using second derivatives. For this time, let's just try to do it by hand. So, I just want to observe. In fact, I can try to, you know, these examples that I have here, there are x squared plus y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared, y squared,  x squared minus x squared, there are sums or differences of squares. And if we know that we can put things as a sum of squares, for example, will be done. So let's try to express this, maybe as the square of something. So the main problem is this 2xy. But, of some we know something that starts with x squared minus 2xy, that is actually the square of something else.  squared, not plus 3y squared. So let's try to do that. So we're going to complete the square. So I'm going to say it's x minus y squared. And then, so that gives me the first two terms and also a y squared. Well, I still need to add two more y squares.  And I also need to add, of course, the 2x and minus 2y. It's simpler, it's still not simple enough for my test. I can actually do better. See, I mean, now what's, so this guy looks like the sum of squares, but here I have this x plus term, but 2x minus 2y, where that's twice x minus y, it looks like maybe we can modify this, and I'm going to show it.  and make this into another square. So in fact, I can simplify this further to x minus y plus 1 squared. See, that would start like the x of x of x parentheses here. That would be x minus y squared plus twice x minus y, and then there's a plus 1. We don't have that plus 1, so let's remove it by subtracting 1.  1 here, and I still have my 2y squared. OK, do you see why this is the same function as that one? Yeah? So again, if I expand x minus y plus 1 squared, and I get x minus y squared plus 2y x minus y, that's those guys, plus 1, but I will have minus 1, then we'll cancel out. And then I have a plus 2y squared.  So now what I know, this is a sum of two squares minus 1, and this critical point xy equals minus 1 0, that's exactly when this is 0 and that is 0. So that's the smallest value.  minus 1 and minus 1 happens to be the value at the critical point. So it's a minimum. Now, of course, here I was very lucky. I mean, in general, I couldn't expect things to simplify that much. In fact, I cheated. I started from that. I  will be a bit different, but you will see it will actually also involve completing squares, just veils more to it than what we've seen. OK, so we'll come back to this tomorrow. How do I know that this equals? Why is what negative one?  xy as something squared plus 2y squared minus 1.  Similarly, y squared is also always non-negative. So, if you add something that's at least 0, plus something that's at least 0, and you subtract 1, you get always at least minus 1. And, in fact, the only way that you can get minus 1 is if both of these guys are 0 at the same time. OK? So, that's how I get my minimum.  So, now about this two more. So, in fact, what I would like to tell you about now instead is a nice application of min max problems that maybe you don't think of as a min max problem.  because I mean, you don't think that that way, because probably your calculator can do it for you, or if not your computer can do it for you. But it's actually something where the theory is based on minimization in two variables. So very often in experimental sciences, you have to do something called list squares interpolation. And what is that about?  well, it's the idea that maybe you do some experiments and you know, you record some data. So, you have some data x and some other data y. And I don't know, maybe for example, x is maybe you're measuring frogs and you're trying to measure how big the frog leg is compared to the eyes of the frog or whatever, or trying to measure something. And if I drink chemistry, then it could be, you know,  how much you put up some reactants and the output of the output product that you wanted to synthesize is generated, all sorts of things. Make up your own example. But so, you measure, basically, for various values of x, what the value of y ends up being. And then you would like to claim, oh, well, these points are kind of aligned. Of course, to a mathematician, they are not aligned. But to an experimental scientist, that's evidence that there's a relation between the two.  So you want to claim, and in your paper you will actually draw a nice little line like that, see, these two functions depend linearly on each other. OK? So the question is, how do we come up with that nice line that best is smacking the middle of the points? So the question is, given experimental data, xi, or x1, is less than  yi, so maybe I should actually be more precise. So you're given some experimental data. You have a data point, x1, y1, x2, y2, and so on, xn, yn.  x plus b, that somehow, you know, approximates very well this data. So, you can also use that, by the way to predict various things. For example, if you look at your new homework, actually, the first problem asks you to predict how many iPods will be on this planet in 10 years, OK, looking at past sales and how they behave.  you know, lose all the money you don't have yet, you can not use that to predict the stock market. So don't try to use that to make money. It doesn't work. So one tricking here that I want to draw your attention to is what are the unknowns here?  So the natural answer would be to say, well, the unknowns are x and y.  the nicest possible line for this point.  OK, so the question really is find the best A and B.  of a and b, that measures the total error that we are making when we are choosing this line compared to the experimental data. So maybe you're awfully speaking, it should measure how far these points are from the line. But now there's various ways to do it, and some of them are, I mean, they're all actually, a lot of them are valid. They give you different answers. You have to decide what it is that you prefer. So for example, you could  to measure of the distance to the line by projecting that monotone Q-l are being. Or you could measure instead the difference for a given value of x, the difference between the experimental value of y and the predicted one. And that's often more relevant because these guys are actually maybe expressing different units. They're not the same type of quantity. So you can't actually combine them arbitrarily.  So the convention is usually we measure distance in this way. Next, we could try to minimize the largest distance. Say we look at where's the largest error and we make that the smallest possible. The drawback of doing that is, experimentally, very often you have one data point that's not good, because maybe you fell asleep in front of the experiment, and so you didn't measure the right thing. So you tend to want to not give too much importance to some data point that's far away from the others.  So maybe instead you want to measure the average distance. Or maybe you want to actually give more weight to things that are further away. And then you don't want to do the distance, but the square of the distance. So there's various possible answers. But one of them gives us actually a particularly nice formula for A and B. And so that's where it's universally used one. And so here it says list squares. So that's because we'll measure actually the sum of the sum of the two.  of the squares of the arrows. And why do we do that? Well, part of it is because, actually, it looks good. I mean, when you see these plots in scientific papers, they really look like the line is, indeed, the ideal line. And the second reason is because, actually, the minimization problem that we will get is, particularly simple, well-posed, and it's easy to solve. So we'll have a nice formula for the best A and the best B.  So, if you have a method that's simple and gives you a good answer, then that's probably the good one. So, we have to define best. And here it's in the sense of minimizing the total square L. So, or maybe I should say,  So what do I mean by that? So the deviation for each data point is the difference between what you have measured and what you are predicting by your model. So that's the difference between yi and a xi plus b.  So now, what we'll do is we'll try to minimize the function capital D, which is just the sum for all the data points of the square of the deviation.  So let me emphasize again, this is a function of a and b. Of course, there's a lot of letters in here. But xi and yi, in real life, there will be numbers given to you. There will be the numbers that you have measured. You've measured all of this data. There are just going to be numbers. You put them in there, and you get a function of a and b.  So any questions? Yes? OK. So how do we minimize this function of A and B? Well, let's use our new knowledge. Let's actually look for a critical point.  we want to solve partial d over partial A equals 0, and partial d over partial B equals 0. That's how we look for critical points. So let's take the derivative of this with respect to A. Well, so it's going to be, well, the derivative of a sum is some of the derivatives.  take the derivative of this quantity squared. So, remember how we take the derivative of the square, we take twice this quantity times the derivative of what we're squaring. So, we get two times minus y i, sorry, y i minus a x i plus b, times the derivative of this with respect to a.  x to a, negative xi, exactly. And so we'll want this to be 0. And partial d over partial b, we do the same thing, but differentiating with respect to b instead of respect to a. So again, sum of squares, twice yi minus a xi plus b, times derivative of this with respect to b is, I think, negative 1.  So, that's the equations we have to solve. Well, let's reorganize this a little bit.  So, see, there's a's and there's b's in these equations. I'm going to just look at the coefficients of a and b. If you have good eyes, you can see probably that these are actually linear equations in a and b. Although, there's a lot of clutter with all these x's and y's, all of other place. OK, so let's actually try to expand things and make that more apparent. So, the first thing I will do is I will actually get rid of this fact.  of two that are not rational, not very important. I can simplify things by two. And next, I'm going to look at the coefficient of A. Well, I will get basically A times xi squared. Well, let me just do it and then it should be clear. So I claim when we simplify this, we get xi squared times A,  xi times c minus xi yi. And we set this equal to 0.  the other one. So we just multiply by minus one. So we take the opposite of that. It will be a xi plus b. I will write that as x xi a plus b minus yi. And I forgot the n here. And let me just reorganize that by actually putting all of the xi a  all the a's together, that means, actually, I will have sum of all the xi squared, times a, plus sum of xi times b, minus sum of xi yi equals 0.  xi. So if I rewrite this, it becomes sum of xi squared times A plus sum of the xi's times B minus 1. Let me move the other guys to the other side. Equals sum of xi yi.  And that one becomes sum of xi times a, plus how many bs do I get from this one?  of R for this one, you look at all your data points for each of them, you take the value of x, and you just sum all these numbers together. So what you get actually is a linear system in A and B, 2 by 2 linear system.  n b. So in practice, of course, first you plug in the numbers for xi and yi, and then you solve the system that you get. And we know how to solve two by two linear systems, I hope. So that's how we find the best fit line. Now, why is that going to be the best one, instead of the worst one? We just solve for a critical point that could actually be a maximum of this error function.  and d. Well, so we'll have actually the answer to that next time. But, trust me, if you really want to go through the second derivative test that we'll see tomorrow and apply it in this case, it's quite hard to check, but you can see it's actually a minimum. So I'll just say, we can show that it's a minimum.  OK, now, even further in the R case is the one that we have the most family on with.  because instead of fitting for the backsline, if you think that there's a different kind of relation, then maybe you can fit in using a different kind of formula. So let me actually illustrate that with an example. So I don't know if you're familiar with Mose-Lau. It's something that's supposed to tell you how quickly, basically, computer chips become smarter, faster and faster over time.  that you can fit onto a computer chip. So here I have some data about, why that? OK. So, OK, better. So here's the data about the number of transistors on, you know, standard PC processor as a function of time. And, well, you know, if you try to do the best line for the machine,  well, you'll see quickly that it doesn't seem to follow a linear trend. On the other hand, if you plug the diagram in the log scale, so the log of the number of transistors as a function of time, then you get a much better line. And so, in fact, that means that you had an exponential relation between the number of transistors and time.  The first law says it says that the number of transistors on the chip doubles every, so depending on conversion, every 18 months or every two years, they keep changing the statement. So how do we find that best exponential fit?  y equals a constant times exponential of a times x. OK? That's what we want to look at. While we could try to minimize a square error, an equated before, that doesn't work well at all. The equations that you get are very complicated. You can't solve them. But remember what I showed you on this log plot. Right? If you plot the log of y as a function of x, then suddenly,  it becomes a linear relation. So, observe, this is the same as ln of y equals ln of c plus ax. And that is a linear, best fit. So, what you do is you just look for the best straight line fit for the real,  of a log of y. So that's something we already know.  So that would mean here, fitting the best parabola for your data points. Well, to do that, you would need to find a, b and c. And now you would have, actually, a function of a, b and c, which would be the sum of all data points of the square deviation.  So now you will have three equations involving A, B and C, and in fact, you will find a three-by-three linear system, and it works just the same way. Just you have a little bit more data. So, basically, you see that these best-fed problems are an example of, you know, minimization problem that maybe you didn't expect to see, minimization problems come in, but that's really the way to handle these questions.  OK, so tomorrow we'll go back to the question of how do we decide whether it's a minimum or a maximum, and we'll continue exploring functions of several variables.
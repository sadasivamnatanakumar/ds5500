 So last time, we proved the fundamental theorem of calculus, and as a consequence, the
integration by parts formula and the change of variables, formula or use substitution, so let me just recall for  is that if I had two, continuous
continuously differentiable functions, then I can shift the burden of taking a derivative, f prime times g,  f of b, g of b minus f of a, g of a, minus the n of a,
or a to b of g prime f. So I can shift that derivative over to from f to g. And this is, apart from the triangle inequality,  one of the most useful theorems that comes out of calculus, other than the fundamental
theorem of calculus, in fact, for those of you who've taken quantum mechanics, which, I mean, you don't have to, but you heard of something called the Heisenberg uncertainty principle, which says something like something to the effect that you cannot measure the position of a particle  it's momentum to arbitrarily, arbitrarily, good degree, you're bound by if you can measure the position of a
particle very well that your measurement of the momentum is going to be not so great and vice versa. And that's based on an inequality and how do you prove that inequality in integration by parts.  one of the great head scratchers for quantum mechanics, so just to back up my claim a little bit. Now, I'm not going to give that as an application, I'm going to
give a different
application related to Fourier series.  and I'm not going to say what type, suppose f for minus pi to pi, R is 2 pi periodic.  200 years ago, you made the following claim that the function f of x can be expanded in terms of simpler
building blocks in terms of simpler  function. So we haven't talked about Taylor series, we will just a
minute or power series, which you've come into contact with, which is a way of if you'd like, expanding a function in terms of polynomials, and now, or monotomials,  be expanded as a super position of functions which are two-pipyriotic and the most basic two-pipyriotic functions. Now, what is so special about sine x and cosine x? Well, this is a little bit deeper, the fact that they satisfy a certain
second-order differential equation, and they are all of the solutions to the second-order
differential
equation that are two-pipyriotic.  So you should think of these as being building blocks, another way to think of this is analogous to if you have a vector.  as a sum of coefficients, a sub n, a sub j, j equals 1 to n, let me make this M, let's make this M, so it looks a little a sub n, where now, e sub n, this is the base  and by 0, 1, 0, where this is in the n spot. So you can think of this expansion in terms of sine and cosine as being analogous to expanding a vector in terms of
basis elements, or you  can think of it as a different way to expand a function other than
taller series, or power series. But these components arose in a natural way if one were to study the problem of heat transfer, which is governed by the equation dt, u equals dx squared,  So condition that u of 0x, so at times 0 equals f of x. So now just like for how we expand a vector into basis elements, there's a formula for computing
these coefficients for computing these coefficients.  they should be a sub n should be x sub n over here, but what's a
different way of obtaining these coefficients? So this is a vector in R m. And so how do you obtain the coefficient  a sub n, well, if I take the product of both sides, the dot product, say, of e, x dot, let's say, e sub n prime, let's say, OK, so I have these Mn, let's say L, this is equal to the sum from n equals 1 to M of a sub n, e sub n, e sub n,
n dot e sub n, e sub L, now I wrote these  these basis vectors this way, because that's kind of a standard choice for Rm, and what makes them
standard is they have unit length and they're orthogonal to each other, so they form an orthonormal basis.  and L, this is 1 if n equals L, and 0 if n does not equal L, and therefore, this just reduces to a L.  setting of a finite dimensional
dimensional vector in our M and expanding in terms of the standard basis here, but it didn't have to be, it could have been, as long as it's an orthonormal basis, then I get this relation that the coefficient that appears in front of that vector is equal to the thing I'm interested in dotted with that vector, which is written here.  So let's say we try and do this same thing now with f of x, except now, and say, so these are functions, so instead of taking dot product, which is a sum of components, let's take an integral.  f of x, and if you like, dotted with sine of x and sum, which is, you can think of as, I said that the
interval is, you should think of maybe a continuous sum, what do we get assuming that this expansion holds? This is equal to the sum from n equals 0, so let me make this L, this is,  the sum from n equals 0 to infinity of a sub n sine n
x times sine, so let me, for getting to write the intervals here, I'm skipping a point I want to make as well.  Lx plus bn cosine nx sine n Lx sine Lx sine Lx, and then n equals 0 to infinity, OK, I'll just write it, stop being lazy. Now, assuming I can do what I'm about to do, and that's actually going to be a lot of the motivation for what we're going to
to discuss  our final chapter, assuming I can take this infinite sum and
interchange it with this interval, this is the interchange of two limits, a sum is an infinite limit, an integration is a limit, so assuming I can switch these two limiting processes,  minus pi pi, pi, sine and x, sine and Lx, sine Lx, plus b sub n
interval, n is pi to pi, cosine and x sine Lx, dx. Now, you can actually sit down and compute this based on  of trigonometric identities, and what you get is that this is always equal to 0, and that this here equals pi times delta n L.  which equals pi times a l. So we get this quantity here is assuming everything we've done is cotier, equal to pi times a sub l. And then to pick up the b sub l is the same, except now you
integrate, again, cosine of l, x.  pi times b sub l is equal to the interval for minus pi to pi of f of x cosine Lx dx.  of the functions of the function f of the function f.  and 2 pi periodic, the numbers a sub n equals 1 over pi, integral from minus pi to pi, f of x sine n
x, dx, dx,  b sub n equals 1 over pi, and our
goal for minus pi to pi to pi, f of x cosine n x, d x are referred to as a 4, a coefficients of f.  And so just using integration by parts, so what's the first question one should ask if it's even possible, or in what sense does f of x equal this infinite sum, well, we haven't even gotten into that, but one question you can ask is do these coefficients that come in front of these basic
building blocks, sine and x  the cosine nx, that they converge to 0, I mean, if we expect f of x to be equal to the sum of these
basic parts, then the contributions from each should be getting smaller and smaller. So does a,n and bn 10 to 0 as n goes to infinity, and this is the content of what's usually referred to as the remon-labored lima, but it's usually stated in a different way,  I'm going to state it this way right now, which is the following, if f from a, b to R is
continuously differentiable,  then limit as n goes to infinity of a sub n equals the limit as n goes to infinity of b sub n equals 0. Now, the actual way the Riemann-Labegg lima is typically stated is, in fact, I don't need it to be
continuously, I just need it to be continuous, this is still true,  what we haven't done or won't do in this class, approximation theorems for continuous functions, which says that if you can do this for
continuously differential functions, and basically you can do it for continuous functions, but this will suffice. So what this says is that the contributions coming from these building blocks is getting smaller, at least in the sense that the coefficients are getting smaller,  thing about if that sum up there with the a and bn's and bn's define this way
actually converges to f, I do want to emphasize that. In fact, trying to straighten out this question, in what sense this series converges to f, is really the motivation for a lot of analysis  last century, in the last part of the century before that, and forms a basis of what's called harmonic
analysis, which is a really beautiful subject and still an active area of ongoing research.  in fact, it'll follow pretty easily from that, let's prove that the limit as n goes to infinity
of b sub n equals 0, the one for a sub n is similar, there's just an x to p, but I'm going to be a little bit lazy and do the 0, 1, we'll show  OK, so let's look at b sub n. This is equal to the n
overrho from minus pi to pi of f of x, and in fact, let me write cosine n x times f of x dx, dx, dx, y, my writing, dx, dx, dx,  do is cosine nx, I can write as the derivative of something, 1 over n times sine nx, if I take the
derivative of that with respect to x, I get cosine nx, and actually prove that, but you can look back in your calculus textbooks, we've proven enough to be able to make that precise.  can now shift the burden of this derivative on to f, but look what I've gained, I've gained a 1 over n here. So now this is equal to 1 over n sine n pi, f of pi minus sine of n minus pi times f of pi minus pi, minus pi,  S 1 over n sine n x minus pi to pi, f prime of x d x. And really what this computation is showing is, illustrating is the oscillatory
nature of what's going on. Cosine of n x is oscillating as n gets very large between minus 1 and 1 and 1, and equal footing.  on average, you're getting the same amount of positive f as
minus as negative f, so or you're waiting f in such a way that it's both positive and negative and equal amounts. Now, sine of n pi, no matter what n is, I get 0, sine of n minus pi, I get 0, so this first part drops off, so this is equal to minus 1 over n, minus pi, pi sine n  times f prime of x d x, and therefore, if I take the absolute value of b sub n, this is less than or
or equal to 1 over n minus pi of pi, sine in x, f prime of x, d x, if I bring the absolute value inside, so I can bring the absolute value  and still get this, so in fact, before when I had the absolute value
outside it to equality, but now it's a less than or inequality, I mean, inequality. Now, sine of n x is always bounded by 1, so this is less than or equal to the integral of f prime of x d x, so this is equal to 1 over n,  Now, this is just f prime. This is just a fixed number times 1 over n, so this converges to 0 as n goes to infinity, and b sub n in absolute value, of course, is
always bigger than or equal to 0, and it's bounded by something converging to 0 as n goes to infinity.  And that's the proof. The proof for the a sub n's is similar, except now you can't throw away, necessarily the end points, but it's still not a very big deal.  And one can prove, and this is proven in classes on, of course, is on harmonic analysis, that, in fact, for a function which is
continuously differentiable, this in 2 pi periodic, this series actually does converge uniformly to f on this interval, and I have even said what uniform convergence means, but actually does converge to the function f of x  So this is the case for a continuous
definity of a function, I'll give a proof, later that this series converges if f is twice continuous,
continuous, we can actually do that using the function by parts,  There are few things here that are behind the scene that are kind of swept away. First off, when we computed these formulas, for me, I guess, we interchange
infinity and infonetimation of functions with integration, when can we do that?  for convergence of real numbers, there was just one sense of the convergence of real numbers. Now, when we have a sequence of functions, which is now what we're going to
turn to, we'll have different notions of convergence to another function, and depending on, in what sense that convergence takes place,  some of these limiting operations may not interchange. So now we're going to move on to the final
chapter of this class, and I know it seems like we're hitting a lot of different things now towards the end of class, and we took it slow during the first part of class, but that's, like I said, that's, I think I even said this at the start of class, we didn't have very much to go off of, we built things from the ground up in the more  things you can prove, the more interesting questions you can ask. So now we're going to go on to
sequences of functions, and you could also put sequences in series because a series is just a special type of sequence of functions.  would be interested in functions converging to other functions or sequences of functions
converging to a function, but we could look at something much more basic. So let's look at take a step back and look at power series, and this should be thought of as motivation for what's to come just like our discussion about Fourier series.  I'm not going to ask any deep questions about 4-year series on the homework or on the exam. So a lot of this is just this discussion was to motivate this theorem here. But now I'm going to make more precise motivation, I guess, for what's to come. So although we've had series forever, I never
brought up power  series, and it's for a reason, it's because I didn't think they belong anywhere until we
got to sequences of functions, so a power series about a point x0 is a series of the form,  a sub j, x minus x0 to the j. So the x0 is given and the things that could change are the coefficients or this number x here.  root test, suppose this number R, which is the limit as j goes to infinity of a sub j, 1 over j exists, so it's a finite number, positive
non-negative number, and define R0 to be  1 over R, if R is bigger than 0, and infinity, if R equals 0.  absolutely, if x minus x0 is less than rho, and diverges if x minus x0 in absolute value is bigger than rho.  the radius of convergence. So again, the proof follows immediately from the root test, because if we take limit as
  this j goes to infinity of a sub j, absolute value x minus x0, j, 1 over j, this is equal to x minus x0, this
kills that j, this is just a fixed number, so this pops out of the limit, and this limit exists, so this equals x minus x0 times  R, and we have two things happening. This is less than 1 if x minus x0 is less than
R0, bigger than 1 if x minus x0 is bigger than R0, this number here. And therefore, by the root test,  the theorem holds. So we see that this series, if you like, what's given are the coefficients a sub j and x0, and what could  that this series converges as long as x minus x
minus x0 is less than or 0, so as long as we say, as long as we say, as long as we say in that interval, a symmetric interval
about x0, then this series converges,  So we can define a function where if I take x in this interval, let's take it into this
series, I get out a number, so define function f, now going from this interval, so x0 minus rho, x0 plus rho to R,  by f of x equals the number that gets spat out by this power series, so I'll put the j there.  let's say I take all of the coefficients to be, let's say x0 is 0, and all the coefficients are 1, so let's say I look at
some of x sub j, then f of x, so we've already computed for a geometric series, this is equal to 1 over 1 minus x for x in minus 1, 1.  minus x is equal x to the j. Another example is that if I take a sub j equals 1 over j factorial, x0 equals 0, then you've done this in an exercise that this
series here,  converges absolutely for all x, meaning R0 equals infinity, and this is how we define the
exponential function.  exponential function, exponential of x to be what comes out of this series, OK? And then simply from this definition, you can show things that an exponential function should satisfy, the e to the n is equal to n
e to the e of 1,  to the n's power and so on and so on, so that this really does obey what you believe an exponential
function should look like, and also it grows faster than any power of x as x goes to infinity, goes to 0 of those types of things. But this is how the exponential function is defined.  inside this interval of convergence. So then I could write f of x as the limit as n goes to infinity of a sequence of functions, because this is just how it's defined, where f n of x is the partial sum.  OK, it's just a polynomial, right? So for a power series, the limit function, you can write it as the limit of the partial sums, which are just polynomials.  we have this. So now, some questions arise, so what this function is equal to the limit of these maybe simpler functions, these simpler functions are just polynomials for the case of power series, so like I said, 1 over 1 minus x is equal to the limit of these polynomials, some questions should arise, I mean,
analysis is about limits,  you can think of that as half the story, first off, what is a limit, what are the important
limiting process that we consider? And the second question is, how do different limits interact? So let's pose that as a question now for a three-parted question, for a power series, and this will motivate  And this is, again, motivating all of what we're going to be doing now. So is the function that I get as this limit of polynomials as the output from a power series, is it continuous?  the partial sums are certainly continuous, they're just polynomials, so is the
limiting thing continuous. Now, if so is f differentiable, and in particular, since f is equal to the limit as n goes to infinity of the f n's, is f prime equal to the limit  as n goes to infinity of the fn prime. So the derivative is a limitative
process, so I'm taking the derivative of the limit, so I'm asking, can I take that derivative inside the limit, can I swap the two processes, and the same with integration?  the interval of f equal limit as n goes to infinity of
intergrals of the f n's. So again, this is a limiting process that we're asking us to flip because f is equal to the limit as n goes to infinity of f n, and what I'm asking  role inside that limit. Now, you can ask these questions not just for power series, but in a more general setting, which is what we're going to turn to now, but this should be in the back of your mind as the
motivation for what we're doing. And apart from being just an academic question,  Apart from being an academic question, it's also somehow giving you information over whether the formal
monitulations that you're doing with Fourier series that are actually somehow modeling some physical phenomenon are these formal manipulations, even meaningful.  we don't have to just stick to the setting of being in power series, this should be a very important
example of a sequence of functions converging to a function, a limiting function, and then we can ask these questions, but we don't have to just stick to power series.  and two modes of convergence for limits of functions, for sequences of functions. So first definition, this is, in fact, what we showed or what we were talking about before,  in a natural number, let fn be functioned from S to R, S is some non-empty subset of
the real numbers, and let f be from S to R. We say, fn, so the sequence of functions  as fn converges pointwise to the function f if for all x and s by stick n x into S. So for each fixed x and S, if I stick this
into fn of x, I get limit, and this limit is f of x.  So for example, going back to power series, if we define f of x, let me just rewrite that example that I had up there, if I define f of x equals 1 over 1 minus x, f of x to be sum from j equals 0 to n of x j,  for all x and minus 1 to 1, limit as n goes to infinity of f n of x equals f of x, i.e, this, the sequence of partial sums of corresponding to this power series converges to 1 over 1 minus x point y, 1 minus 1, 1, 1, 1.  So I say, whenever you come across a definition, you should negate it, but the negation of this definition is not too difficult.  of x. So let's look at another example, which is not a power series. Let's say we take fn of x to be x to the n, where x is in the closed
interval 0, 1. So what's happening here is n gets very large, there's 1,  1, there's, I don't know, f 5 of x, and then as n gets very large, these guys are dropping down even more and more. And what is, are we picking up something in the limit? Well, let's look, if x equals 1, it's pretty clear that the limit as n  goes to infinity of f n of 1, this equals 1. If I stick in 1 here, I get 1 for all n, and therefore, the limit as n goes to infinity
of f n of 1 is 1. Now, if x is n 0, 1, we've done this limit before, the limit as n goes to infinity of f n of x, this is equal to the limit as n goes to infinity of x,  is less than 1, so x is being raised to a
higher and higher power, this equals 0. Thus, what do we conclude?  of x, which is equal to 0 if x is in 0, 1, and 1 if x equals 1. So I draw another picture here of what the limit looks like,  And you can start to start to see this as n gets large, again, this is becoming more
vertical there, but then going to 0, so for any fixed n, it's converging to this picture on the right.  a question about convergence of functions in the point y
sense, so we could have asked this question now, after having this definition, suppose f n's are continuous, converging point y's to a function f, is the function f continuous. And what this example shows is, no, that's not the case, x to the n is always continuous, yet the limit as n goes to infinity, the pointy's limit is given by this function, which  0 from 0 to 1, and 1 at x equals 1, which is not a continuous function. So already, we're kind of saying that pointy is convergence, which is this first weakest
motive convergence that we, as of now, can say about power series and is not good enough to ensure that the limit is
even continuous, because this example  shows that we have a sequence of continuous functions, whose pointy limit is
not continuous, which is not continuous. So as another example, you should always like this kind of last chapter, because you can draw a lot of pictures,  So I'm going to draw pictures of fn, so it's p-swise linear. So I could write down what the function is, but I don't want to, I'm just going to draw a picture.  the function f n of x is 0 up until n, and then it's a linear function
connecting 1 over n to 2n here, and then it connects this point 2n0, so I should say 1 over 2n 2n, connects that to the origin.  linear. So for example, if I wanted to draw f1, f1 would look like there's 1, 0, 2, 1, 1, 1, 1, 1, 1, and let's say I wanted to draw f100, what does that look like?  there's 1, 1 over 100, and then that should be 1 over 200, and then if I go up to 200, this is this p-swise linear function,  getting it's 0 from 1 up to 1 over 100, so it's 0, most of the time, and it's 0 at the origin, but in this M
between is very tall and very slim.  0, 1, limit as n goes to infinity of f n of x equals 0. So this sequence of functions
converges point y is to 0.  rather than me talking it out, I'll talk it out and give it a full proof.  1 over 2n, 2n, 2n here, and then down to 1 over n0, and then there's 0
between that and 1. So first off, if x equals 0, then all these functions are 0 at the origin, so the equals 0, so that equals 0.  So that's fine. So now suppose x is in 0, 1, and so what do we want to show? I want to show limit as n goes to infinity of f n of x equals 0.  And here, so what's the point here? Now, there's 1, there's x. So I have to give an epsilon delta, epsilon m argument, I'm just going to show you what happens.  Now, let's choose a very large integer, so that 1 over m is less than x.  x equals 1 to x equals 1 over m, and then shoots up and then comes back
down over here to 0, but here's the point. It's 0 all the way from 1 to 1 over m, so in particular, at x, fn of x is 0.  So no, it is f 1 of x, f 2 of x, up to f n minus 1 of x, and then at f m of x, so at the, now, so this is f m of x spot, it's 0. And this point is only going to the left.  Now, this will be 1 over n will be to the left of x, and therefore, f n of x will be 0. So this is 0, 0, 0, 0, 0, and so on. So I have the sequence is eventually 0 for all n bigger than or equal to capital M,  So, and therefore, the limit, I mean, it's pretty easy to take a limit of a constant
sequence, which proves that this sequence of functions converges point-wise to 0. Now, I didn't come up with this fancy example for just any old reason, it'll come back in a minute  when we start answering some of these questions or asking them, again, within the context of these two
convergence, ways of converging. So far, I've only given you one definition of convergence point y is convergence of a sequence of functions. And now, I'm going to give a slightly stronger, it's not slightly, it's much stronger,  definition of convergence of a sequence of functions. So we have a sequence of functions and a given function from S to R, S is a non-empty subset of R,  this sequence, fn converges pointy or uniformly to 0, uniformly to 0, uniformly to 1, if I start mixing up some of my words, I'm always going to
correct it, but the first word out of my mouth may not be the correct one, converges uniformly to f of x,  Now, if, now we have an epsilon n statement for all epsilon positive, there exists an M, natural
remember, such that for all n bigger than or equal to M, for all x and S, f n of x minus f of x is less than epsilon,  Now, I want to make a brief comment, this looks, suspiciously like point-wise convergence, if you just
wrote down what it means for the limit as n goes to infinity of fn of x goes to f of x, except there's a very subtle and important point, and that is where does the for-all x and S appear.  being at the start of the line for all x and S, for all positive
positive, blah, blah, blah, blah, blah, blah, here, it appears at the end of the line of the quantifiers. And this makes a very important difference between point-wise convergence and uniform convergence. Point-wise convergence means I take a point x, I stick it into f n of x, that gives me a sequence of numbers, and point-wise convergence says that
sequence of numbers  converges to f of x. For each x, I get a sequence of numbers, which
converges to f of x. Now, uniform convergence is actually saying something stronger.  let's say my limiting function is f is given by this graph, and so what I'm going to do is basically shift the graph up and down by
up and down by it.  epsilon, meaning this length is epsilon, and so is this length all the way across. So let me show you this n, and real line, so I get this little, if you  shaded area around my function f, so this is f, f of x, that's the graph, and the shaded part, this is the set of all x and y, such that f of x minus y is less than epsilon.  that for all n bigger than or equal to some M, so given epsilon for all n bigger than or equal to M, if I were to draw the graph
of fn of x, it better fall inside this 2 across all of a, b. See, this 2 is defined for all x between a, b. So it's making a statement about how close fn  of x is to f of x across the entire set. Pointy as convergence just says, if I put an x
into fn of x, then eventually that number is those numbers are getting close to f of x. Uniform convergence is a global property.  fixed in x, the fn of x at that point are converging to f of x. So I've said a couple of times that
uniform convergence is stronger than point-wise convergence, so let me actually prove this now.  So if I have a sequence of functions from S to R, and fn, rather than
right converges to f point y's or uniformly, I'm going to put an arrow, and then with the description afterwards, uniformly on S, then this implies f  then converges to f point y's on S. So it's very simple. Again, what is the picture that's going on for uniform convergence is that f n is getting close to f
across the entire set that we're looking at. So certainly at one point, which is all you need for point y's convergence, each fixed point, we should be getting close.  let epsilon be positive. So first off, let's fix a number in the set S. So now we want to prove that the limit as n goes to infinity of fn of c equals f of c, let epsilon be positive,  since fn converges to uniformly, uniformly, there exists a natural number M0 such that for all n bigger than or equal to M0, for all x in S, fn of x minus f of x is less than epsilon.  m to be this M0, the M that is for this epsilon, then for all n bigger than or equal to M, let's
call this equation star star with at the single point x equals c implies f n of c minus f of c is less than epsilon  And thus, the limit as n goes to infinity of f of c, fn of c equals f of c.  that, in fact, so this is a one-way street, meaning point-wise convergence does not imply
uniform convergence. So we just proved uniform, and the point-wise, but the converse does not hold. And what we'll prove next time is, in the setting of this simple example of x to the n,  And so what we'll prove next time is the following, if I take any b between 0 and 1,  then fn converges to f uniformly on the set 0, b. So these functions are defined on 0, 1, so they're
certainly defined on 0, b for b less than 1.  functions does not converge uniformly to f on 0, 1. So here, this second part, since the fn's converge to f point y's on 0, 1, the second part says that this is a 1-way street, this is not a 2-way street,  modes of convergence, uniform convergence, and
point-wise are not equivalent.
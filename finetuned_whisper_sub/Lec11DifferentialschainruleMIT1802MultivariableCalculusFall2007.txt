 The following content is provided under a Creative Commons license, your support will help MIT open courseware continue to offer high-quality
educational resources for free to make a donation or to view additional materials from hundreds of MIT courses, visit MIT open courseware at ocw.mit.edu.  of two variables of several variables, and now we try to study more in detail how functions of
sevalle variables behave, how to compute their variations, how to estimate their variation in arbitrary directions, and so far that we're going to need some more tools, actually, to study these things.  functions, and so today's topic is going to be differentials, and just to motivate that, let me  OK, mind you about one trick that you probably know from single
viable calculus, namely implicit differentiation. So let's say that you have a function y equals f of x, then you would sometimes  dy equals f prime of x times dx, and then maybe you would, can you please take a set and set down that would be letter, thank you.  changes in y within, if it is a small change in x, and one thing we can do with that, for example, is
actually figure out the rate of change dy by dx, but also the rest of the proof, dx by dy.  x equals sine of y, and from there, we can actually find out what is the
derivative of this function if we didn't know the answer already by writing dx equals cosine y dy, and so that tells us that dy over dx is going to be 1 over cosine y,  for relation to sine is, basically, one of L square root of 1 minus x squared, and that's how you find the
formula for the derivative of the inverse sine function. Formula that you already knew, but that's one way to derive it.  but use them for functions of several variables, and of course, we'll have to
learn what other rules of manipulation and what we can do with them. So the actual name of that is the total differential, as opposed to the partial derivatives, because, well, it's going to be a total differential, because it includes all of the
of the
sequences that can  And sorry, all of the contributions that can cause the value of your function f to change. So namely, let's say that you have a function f, maybe of x, y, g, then you will write df equals f sub x dx plus f sub y dy plus f sub g dz.  just to remind you of the other notation, partial f, partial x, dx plus partial f, partial y, dy plus partial f of our
partial z, dz. Now, what is this object? What are the things on either side of this equality? Well, they're called differentials, and they're not numbers, they're not vectors, they're not matrices, they're a different kind of object.  So this things have their own roles of
benefulations, and we have to learn what we can do with them. So first of all, how do we not think about them?  the f is not the same thing as delta f. So that thing is meant to be a number. It's going to be a number, once you have a small
valuation of x, a small variation of y, a small variation of z, these are numbers, delta x delta x delta, where delta is the actual numbers, and this becomes a number.  all you can do with a differential is x-press it in terms of
over differentials. So in fact, this dx, dy and dz, well, there are mostly symbols out there, but if you want to think about them, they're the differentials of x, y, and z. So in fact, you can think of these differentials as placeholders where you will put other things. So of course, the represent, there's this idea of
of changes in x, y, z, and f,  But so one way that one could explain it, I don't really like that, is to say there
represent infinite asimple changes, another way to say it, and I think that's probably close out to the proof, is that these things are somehow place holders to put values and get a tangent approximation.  we'll actually get a numerical quantity, and that will be an
approximation for the infimumula for delta f, it will be a linear approximation of the tension playing approximation. So what we can do, well, so let me start first with maybe something even before that. So the first thing that it does is it can encode  changes in xyz effect the value of f. I would say that's the most general answer to what is this formula, what R is differentials, it's a relation between xyz and f.  for small variations, delta x, delta y delta z to get an approximation from you.  delta y plus f of the delta z, so it's getting clamped, but I'm sure you know what's going here. And observe how this one is actually equal, while that one is
approximately equal, so they're really not the same. Another thing that the notation suggests we can do, and the claim we can do, is divide everything by some variable that
everybody depends on, so say, for example,  that x, y and z actually depend on some
parameter T, then they will vary at a certain rate, dx, dT, dy, dT, dz, dT, and what the differential will tell us, then, is the rate of change of f as a function of t when you plug in these values of x, y, z.  So the third thing we can do is divide by, say, something like dt to get an infintensational rate of
changed, by an instant,  let me just say a rate of change. So df dt equals f sub x dx dt plus f sub y dy dt plus f sub z dz ddt, and that corresponds to the
situation  where x is a function of t, y is a function of t, and z is a function of t, then that means you can plug in these values into f to get, well, the value of f will depend on t, and then you can find the rate of change with
t of a value of f. So these are the basic rules.  And this is known as a chain rule, it's one instance of a chain rule, which tells you when you have a function that depends on something, and that in turn, depends on something else, how to find the rate of change of a function on the new variable in terms of the derivatives of a function, and also the dependence between the
value of the variables.  Any questions, so far? No? OK, so a word of warning, in particular, about what I said up here, it's kind of unfortunate, but the textbook actually has a series mistake on that. They do have a couple of formulas where they make a deal with the delta, and they would like you not to do that, please.  And there's d's and there's delta's, and basically we don't live in the same
world, we don't see each other. The textbook is lying to you.  don't really need to justify it because the first one is just stating some general
property that I'm not making a precise mathematical claim, the second one, well, we know that the approximation formula already, so I don't need to justify it for you.  well, we can do that, which I can't have pulled it out of my hat, I mean, I don't have a hat.  So let's see, well, we say df is f sub x dx plus f sub y dy plus f sub z dz. But we know, well, if x is a function of t, then dx is x prime of dt, or dx dt, dt, dt, as you prefer.  dy is y time of t dt, dz is z prime of t dt. So if we plug these into that formula, we'll get that df is f sub x times x
t of dt plus f sub y, y  of t dT plus f sub z, z prime of t dT. And now, if I have a relation between df and dT, I got df equals something times dT, that means the rate of change of f with respect to
t should be that coefficient.  then I get the formula that's what I get the chain hole. Now, well, that kind of works, but that shouldn't be completely satisfactory, let's say that you're at whose skeptic, that you don't believe in
differentials yet, then it's maybe not very good that I actually used more of this  for notations in deriving the answer. So that's actually not how it's proved, the way in which you
prove the chain rule is not this way, because we shouldn't have too much trust in differential adjust yet. At the end of today's lecture, yes, probably we should be leaving them, but so far we should still be a little bit reluctant to believe this kind of strange objects  And here's a better way to think about it. So one thing that we have thrust in, so far, our
approximation of formulas, because we should have thrust in them. So we should believe that if we change x a little bit, if we change y a little bit,  then we are actually going to get a change in f that's
approximately given by these guys. So now, well, this is true for any changes in x, y, z, but in particular, let's look at the changes that we get if we just take these formulas as functions of time and change time a little bit by delta t.  changes in x, y, g in a small time delta t. And let's divide everybody by delta t. OK, here, I'm just dividing numbers. So I'm not actually playing in the tricks on you. I mean, we don't really know what it means to divide the
dividing numbers, but dividing numbers is something we know.  if I take delta t very small, then this guy tends to the d-fantasy, sorry, tends to the derivative, df dt. Remember, the definition of df dt is the limit of this ratio when the time interval delta
t tends to 0. So that means if I choose smaller and smaller values of delta  then these ratios of numbers will actually tend to some value, and that
value is the derivative. So similarly, here, delta x over delta t, when delta t is really small, will tend to the derivative dx dt.  So, so if we take the limit as delta
times to 0, we get the  f dt on one side, on the other side, we get f sub x dx dt plus f sub y dy dt plus f sub z dz dt, and the approximation becomes better and better. Remember, when we write
approximately equal, that means that it's not quite the same, but if we take smaller and smaller and
smaller variations, then actually we'll end up with values  getting closer and closer, so then we take the limit as delta
times to 0, eventually we get an equality.  if you go in that direction. OK, any questions so far? So let's check maybe things in an example, let's say that we really don't have any fave in this thing.  So let's say I give you a function that's x squared y plus z, and let's say that maybe x
will be t, y will be e to the t, and z will be sine t.  So what does the chain hold say? Well, the chain hold tells us that dw, dt is, so we start with partial
dw, the partial x, well, what is that? 2y times, so maybe I should point out this is dw sub x.  times dx dt plus, well, w sub y is x squared times dy dt plus w sub z, that's going to be just 1, dz dt.  in the actual values of these things. So x is t, y is e to the t, so that will be 2, t, e to the t, dx dt is 1, plus x squared is t squared, dy dt is e to the t, plus dz ddt is cosine t.  the end of calculation we get 2t e to the t plus t square
e to the t plus cosine t, that's what the chain-hole tell us is. How else could we find that? Well, we could just plug in values of x, y and z, x plus w as a function of t and take it's derivative.  And in fact, in this case, the two calculations, the two
calculations are hopefully equal in complication. But say that your function of x, yz was much more complicated than that, or maybe you actually didn't know a formula for it, you only knew it's partial derivatives, then you would need to use the chain rule.  So let's just check quickly. So the other method would be to substitute. So w as a function of t, well, so remember,
we'll remember, w was it x squared y plus 0,  so as a function of t, well, x was t, so you get t squared y is e to the
t plus 0 was sine t. So dw, dt, we know how to take a derivative using single variable calculus, well, we should know, if we don't know, then we should take a look at 18 or 1 again.  the t plus t squared times the derivative of e to the
t is e to the t plus cosine t. And that's the same answer as over there. So I ended up writing up, maybe I vote slightly more here, but actually, the amount of calculation, so it was pretty much the same.  OK, any questions about that? Yes. What kind of object is w? So, well, I was in tending, you can think of w as just an other variable that's given as a function of x, y and z, for example. So you have a function of x, y, z, defined by this formula. And I call it w, or I call it value, w, so that's then I can
substitute x to the x, y, z.  So, let's think of w as a function of free variables, and then when I plug in the
dependence of this free variable on t, then it becomes just a function of t.  OK, any other questions? OK, so let's see, here's an application of what we've seen. So let's say that you want to understand, actually, all these rules about taking derivatives in single
value variable calculus. So what I showed you at the beginning and then erased, basically,  if I is how to take the derivative of a for a reciprocal function, and for that you didn't need
multivariable calculus, but let's try to justify the product hold, for example, for the derivative.  So let's think, for example, of a function of two
variables, u and v, that's just a product, u, v. And let's say that u and v are actually functions of one variable t.  will apply to f, this is df dT. So df dT should be f sub u, d, d, e, dT, plus f sub
v times dV dT. But now, what is the partial of f with respect to you? It's v. So that's d, d, e, d, d, e, dT, and partial of f with respect to b  just you. So you get back the usual product. That's a slightly complicated way of driving it, but that's a valid way of understanding how to take the
derequality of a product by thinking of the product first as a function of two variables, which are a u and b, and then saying,  variable t, and then you do the differentiation in two
stages using the chain rule. Similarly, you can do the quotient hold, which will less do it just for practice. So if I give you the function g equals u of R, so right now, I'm thinking of it as a function of two variables, u and v, but
up and v, then,  then dg dt is going to be partial g, partial u, how much is that?  What's the derivative of this with respect to V, well, here we need to know how to
differentiate the inverse, it's minus u over of x squared times dVdT. And that's actually the usual proof and hold just for it in a slightly different way.  If you clear the denominator to put the
with a v squared, then you will see, basically, the u prime times v minus d prime times  OK, now let's go to something even more.  even more crazy, I claim we can do chain rules with
more variables. So let's say that I have a quantity, let's call it w today, for now. So let's say I have 1tw, it's a function of, say, 2 variables x and y, and so in the previous set up, x and y  they're dependent on some parameter t. But actually, let's now look at the case where x and y of M
serves are functions of several variables, let's say, of two more variables, let's call them u and v.  think about it maybe in terms of something you might know, say, polar coordinates, let's say that I have a function, that's defined in terms of the polar
cordinate variables R and theta, and then I know that I want to switch to a
cordinity of x and y.  a variables related to each other. So one way I could do it is, of course, to say, well, now if I plug the formula for x and the formula for y into the
fambula for f, then the w becomes a function of u and v, and I can try to take its partial derivatives, if I have explicit formulas,  but maybe the formulas are complicated. Typically, if I switch between rectangular and polar coordinates, there might be an inverse trick, there may be maybe an arc tangent to express the polar angle in terms of x and y. And then I don't really want to actually substitute
actantions everywhere, maybe I would rather deal with derivatives.  question is what are partial w over partial u and partial w of a partial
value of a partial v in terms of, so let's see, what do we need to know to understand that? Well, probably we should know how w depends on x and y if we don't know that, then we're probably  x, p of the value of x, p of the value of
value, p of y should be required. What else should we know? What it would probably help to know how x and y depend on you and v? If we don't know that, then we don't really know how to do it either.  So let's see how we can do that. So let's stop by dividing dw. So we know that dw is partial f, well, I don't know why I have two
names, w and f. I mean, w and f are really the same thing here, but let's say f sub x, dx plus f sub y dy,  So far, that's our new front, the differential. Now, what do we want to do with it? Well, we'd like to get rid of dx and dy because we'd like to express things in terms of the question we're asking ourselves, is let's say that I change
you a little bit, how does w change? So of course, what will happen is if I change you a little bit, then x and y  how do they change, what if it's given to me by the differential? So dx is going to be, well, I can use the differential, again, dx, well, x is a function of
fn of u and v, that will be x sub u times d, plus x sub v times db, that's again taking the differential  a function of two variables, does that make sense? Then we have the other guy, f sub y times what is dy? Well, similarly, dy is y sub u, d u plus y sub d, db. And now we have a relation between d, w, and d, and db, we're expressing how w react to
change is in new and b.  which was an ago. Now, let's actually collect terms so that we
see it a little bit better, so that's going to be f sub x times x times x sub u plus f sub y times y sub u d,  So now we have dw equals something dup plus something db, well, that coefficient here has to be partial f, partial
u, what else could it be? That's the rate of change of w with respect to you if I forget what happens when I change v.  that because it's the rate of change with respect to V if I keep you constant so that these guys are
complete the ignored. So now you see how the total differential accounts for somehow all the partial derivatives that come as coefficients of the individual variables in these expressions.  as a way, and then we explained them to you. So here's the chain rule for this situation with two
intermediate variables and two variables that you express these in terms of. So in our setting, we get partial f of our partial u equals partial f of our partial x,  partial f of a partial y times partial y of a partial y
of a partial y, and the other one, same thing with v instead of u, partial f, partial f, partial x times partial x, partial x, partial x, partial x, partial v, plus partial f, partial y, partial y, partial y, partial y, partial v.  because they look complicated, and actually they're not that complicated. So a couple of things to know. First thing, so how do we remember a
formula like that? Well, that's easy. We want to know how f depends on you. What does f depend on, actually? It depends on x and y. So we'll put partial f, partial x and partial f, partial y. Now, x and y, y are over here, well, they're here because  actually depend on you as well. How does x depend on you, well, the answer is partial x, partial
x, partial u, how does y depend on you, the answer is partial y, partial y, partial y, partial y, partial u? So see, the structure of this formula is simple to find the partial of f, with respect to some new variable, you use the partial, with respect to the variables that f was initially defined in terms of x and y, and you multiply them by the
partial of x and y in terms of the new  so I able that you want to look at
at, V here, and you sum these things together. So that's the structure I will form you up. Why does it work? Well, let me explain it to you in a slightly different language. So this asks us, how does f change if I change you a little bit? Why would f change if you change it a little bit? It would change because f actually depends on x and y, and xn, and y  if I change you, how quickly does x change? Well, the answer is partial x, partial
x, partial u. And now if I change x at this rate, how does that cosy f to change? Well, the answer is partial f, partial x times is gay. Well, at the same time, y is also changing. How fast is y changing if I change you?  f, f alpha or y. So the product is the effect of how you change is changing y and
therefore, changing f. Now, what happens in real life if I change you a little bit? Well, both x and y change at the same time. So how does f change? Well, it's the sum of the two effects. Does that make sense?  OK, here's another thing that maybe a little bit confusing. So what is tempting here would be to simplify this
formulas by removing these partial x's? So let's simplify by partial x, let's simplify by partial y, we get partial f of f of f of f plus f of you equals partial f plus
f plus partial f of f of f of f of f of f of you, something is not working properly.  these are not total derivatives, and so you cannot simplify that way. And that's actually the reason why we use this curly d, or have an
strategy, it's to remind us be where there's these simplifications that we can do with straight d's that are not legal here. So somehow, when you have a partial derivative, you must  get any questions at this point?  of expression in terms of those variables, but ultimately, what you care about is not
nots those variables x and y, but another set of variables here, u and v. So x and y are giving you a nice formula for f, but actually the relevant variables for your problem are
upon your
problem, and you know how x and y are related to you and v. So of course, what you could do is you could plug the formula, the way that we did substituting, but maybe that will give you very complicated  So the important claim here is, basically, we don't need to know the actual
formulas, or we need to know if the rates of changes. If we know all these rates of change, then we know how to take these derivatives without actually having to plug in values.  then it would be the same thing, and you would have the same formulas that I had, well, over there, I still have it. So why does that one have straight these? Well, the answer is I could put curly d's if I wanted, but I end up with a function of a single variable. So if you have a single variable, then the partial with respect to that variable is the same thing as the
usual derivative, so we don't actually need to worry about curly in that case.  two variables, you and V, they depend on a single
value of a single variable t. Now, of course, whether you call your variable, you know, any name you want, it doesn't matter. So this is just a slight generalization of that, well, not quite, because here I also had a g. I'm trying to just confuse you by giving you functions that
dependent, various numbers of variables. If you have a function of 30 variables, things work the same way, which is very long, and you're going to run out of letters in the  OK, any other questions?  a new value of a value of a value of a
sub-functional, sorry, so if you, if you, if you, in a few n, we're dependent on the
init and a new at an of our variable, then you could get the derivative, we respect to that, using first, the chain rule to pass from you to that new variable, and then you would plug in this formula for the partial of f respect to you and you, so in fact, if you have several of the substitutions to do, you can always  and probably at that stage, the easiest to not get confused, actually, is
to manipulate differentials, because that's probably easier.  for the rate of change, with respect to that variable,
leaving the over-ers fixed, while straight df is somehow a total variation of f, and so it accounts for all of the partial derivatives  So one example where concretely, you might want to do this is you have a function that you want to switch between
requind your rectangular and polar coordinates, so just to make things a little bit more concrete. So if you have polar coordinates, that means that in the plane, instead of using coordinates x and y, you will  R distance to the origin and f of the angle from the x axis. So the change of
value for that is x equals R cosine f, and y equals R sine f. And so that means, well, if you have a function f that depends on x and y, then, in fact, you can plug these and get a function of R and f  well, what is partial f of the partial R? And that's going to be, well, you want to take partial f, partial x, partial x, partial x, partial R, plus partial f, partial y, partial y, partial y, partial R, and so that will end up being, actually, f sub x times cosine theta, plus f sub y times sine theta.  do the same thing to find partial f partial f, partial f, so you can express
the derivatives, either in terms of xy or in terms of R and theta, with simple relations between them.  a gradient vector. So the gradient vector, it's simply a vector, so you use this done what
pointing triangle as a notation for the gradient, it's simply a vector whose components are the partial derivatives of a function. So in a way, you can think of a different way to a way to package partial derivatives together into some weird object,  way to package powerful together. So we'll see on Thursday what it's good for, that some of the
problems on the p-set use it.
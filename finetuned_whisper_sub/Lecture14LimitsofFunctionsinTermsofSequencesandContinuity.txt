 Last lecture, we introduced the notion of the limit of a function as x goes to c, which we write limit x arrow c, f of x equals L, what does this mean?  is less than x minus c is less than delta, we have that f of x minus L is less than
epsilon. And we proved the following theorem last time that if we have a set, a cluster point of S, so this is where we look at limits and f as a function from S to R, then the limit as x goes to c of f of x equals L, if and only if for every sequence  x sub n converging to c, we have f of xn, a new sequence converges to L. So this theorem here,
connects limits of functions to what we did previously, limits of sequences. Now, using this theorem, we'll get analogues of theorems we prove for sequences, but now for  limits. First, let me show a few simple
applications of this theorem. So for example, we could prove the following at for all c in R, limit as x goes to c of x squared equals c squared.  using just the definition, but now with this theorem, we can prove it a little bit
quicker and easier because we essentially did all the hard work when we proved that the product of two convergent sequences is convergent, which is what we'll use here.  So in this, for this theorem, since it's not stated, you should take the function to be f of x equals x squared, and then the set that is
defined on S is equal to R. So let xn be a sequence such that xn converges to c as n goes to infinity, we now want to show that f of xn converges to f of c, where f of x  x squared, but this follows from what we proved for limits, so we proved the product of two
convergent sequences is convergent by earlier theorem about the product of convergent  So in sequences, we get that xn squared converges to c squared, which implies, so we've now verified for every
sequence converging to c, f of xn, meaning xn squared converges to c squared, and therefore, by the previous theorem,  we've proven the claim. So now let's use the theorem to study a couple of more limits, and we use this theorem, in fact, to show that a certain
limit does not exist.  limit as x goes to 0 of sine 1 over x, this limit does not exist. So remember, for a limit, I look at all those points x that are close to c, but not equal to c.  doesn't need to be defined at x equals 0 in order to
consider the limit, and if you like, the function sine of 1 over x is defined on S equals R takeaway 0. So this limit does not exist, but the limit as x goes to 0 of x times sine of 1 over x does  Now, I want you to note something, you can't just stick in x equals 0 here to
evaluate the limit because then you'll be taking sine of 1 over 0 times 0, you can't divide by 0. So you can't just say this limit equals 0 because I stick in x equals 0. In fact, we saw in the previous lecture that the limit need not equal the function evaluated at that point  So just to recall the example from last time, when I had f of x equals 1 if x equals 0 and 2, if x is not equal 0, and we showed that limit as x goes to 0 of f of x equals 2, which does not equal f of 0.  the limit to the function evaluated at that point, I just want to make that little
comment. OK, to prove this theorem, we're going to use, again, the previous theorem, maybe I should, no, I'm not going to label it, you'll know when I point up to it that I'm referring to that theorem that I stated up there.  limit exists and equals 0 first. So suppose xn is a sequence converging to 0, we now want to show that x sub n times sine of 1 over x sub n
converges to 0, and then that by the previous theorem up there,  imply that the limit as x goes to 0 of x times sine of 1 over x
equals 0, if I look at the absolute value of x sub n times sine of 1 over x sub n, this is equal to the absolute value of x sub n times the absolute value of sine of 1 over x sub n, and no matter what you stick into sine,  sine is always bounded between 1 and minus 1, so the absolute
value is always bounded by 1. So just to summarize, we've shown that, and now we apply the squeeze theorem.  since x sub n is converging to 0, remember we're assuming that this
converges to 0, and therefore, what gets trapped in between goes to 0.  OK, so now we'll prove 1, and in the previous lecture I did negate this definition, so let's actually negate this
theorem, if you like, or use the negate this theorem  of each side of this if and only if to state an equivalent theorem, so two statements are equivalent, which is in that theorem, if and only if their negations are also equivalent, so the theorem we also have the following fact, limit x goes to c of f of x is not
equal to L, if and only  if there exists, so negating the right-hand side of that if and only if there exists a
sequence xn converging to c, so this sequence will, consisting of elements of S takeaway c such that xn  converges to c, but we don't have f of xn converging to L. And when I write this, you should read this as either this limit exists, and does not equal L or this limit
does not exist.  and write that out. So, and either limit does not exist or does not equal L. So, again, that's an equivalent way of stating  Up there is in terms of the negation, two statements are
equivalent, which is right there if and only if their negations are equivalent.  that there exists a sequence converging to 0 such that when I plug that n to sign, the limit of that
sequence does not exist. So to show there exists a sequence converging to 0 such that  limit as n goes to infinity of sine of 1 over x, sub n does not exist. Now, sine oscillates between 1 and minus 1, depending on if I'm a certain
multiple of pi over 2. So here's the n  I've wished in behind it behind the sequence I'm about to give you, note that sine of x equals 1 if x equals pi over 2, pi pi over 2, 9 pi over 2, and so on,  minus 1 if x equals 3 pi over 2, 7 pi over 2, 11 pi over 2, and so on. So I can stick in things that are getting bigger to sine and get 1 or minus 1.  to be essentially 1 over y. So if I stick n pi over 2, 5 pi over 2, 9 pi over 2, 9 pi over 2, and so on, I get sine equals 1, if it's 3 pi over 2, 7
and 7 pi over 2, 11 pi over 2, and I stick that n to sine, I get minus 1. But that means if I stick 1 over these numbers into sine of 1 over x, I get 1 or minus 1.  will be 1 or minus 1 alternating, and we know that
sequence does not converge. So that's the idea, so let me write that down.  1, because we're going to stick this
into sine of 1 over x, which is 2 over 2n minus 1 over pi, OK? Now, note, for all n, x sub n is less than or equal to, I can write  that this says 2 over n plus n minus 1 pi, and since n is bigger than or equal to 1, this is
always bigger than or equal to 0, so this is less than or equal to 2 over n pi, and this goes to 0. So that shows by the squeeze theorem that this sequence I've defined here converges to 0.  1 over x, this is now equal to sine of 2n minus 1 pi over 2, and this is therefore equal to 1 minus 1, 1, 1, 1,
minus 1, 1, 1, 1, 1, minus 1, 1, 1, minus 1,  And this sequence, which is just equal to minus 1 to the n plus 1, y capitalized that, does not converge.  take it into the function that new sequence does not converge, so we've proven that this limit does not exist.  All right, so I alluded to this fact that this theorem will give us theorems that are similar to what we prove for sequences, except now for limits of functions. So let me just state the simplest theorem you can get.  let S be a subset of R, c a cluster point of S, and suppose I have two functions, f going from S to R, and g going from S to R.  if these two limits exist, and 1, 1 function is smaller than the other,  then, so we had an analogous statement for sequences, which was if I have two sequences converging, and 1 is less than or equal to the
other, then the limits are, one limit is less than or equal to the other, and it's an analogous conclusion for limits of functions.  So again, the analogous statement for sequences was we have two sequences, one less than or equal to the other, which then the limit of the
smaller sequences less than or equal to the limit of the bigger sequence.  limits of functions to limits of sequences, and then we'll use the corresponding
statement, which we do have for sequences, which I just stated a couple of times.  do, right? OK, let xn be a sequence in S take away c such that xn converges to c.  c is a cluster point of S, you proved in the assignment that if I have a cluster point of S, then there
exists a sequence in S take away c that converges to c. Now, since, say it this way, by the previous theorem, this limit equals L1, this limit equals L2, if and only if for every sequence converging  f of xn converges to L1, g of xn converges to L2. By the previous theorem, we then conclude that L1 is equal to the limit as n goes to infinity, actually, again, the
head of myself a little bit. So let's pause right there and reset. So now we have the sequence converging to c,  then by the assumption here, for all n, f of xn is less than or equal to g of xn, and since f of xn converges to L1, and f of xn converges to L2,  we get by, again, this theorem about sequences, which says if I have two
sequences, f of x sub n, this is one sequence is less than or equal to another sequence g of x n, and they both converge, then the limits satisfy the same inequality.  which is what we wanted to prove.  I said, this theorem here follows from the analogous, in fact, I should have written this out, or in fact, I will
write it out now. So the analogous statement for sequences was if for all n, a n is less than or equal to bn, then limit as n goes to infinity, assuming  limits exist satisfy the same inequality. So this is an analogous theorem to this theorem which we had for
sequences, and we used this theorem from sequences to prove it. Now, following that same philosophy, you can prove analogous statements for functions, limits of functions, as you did from sequences, you get these for free, instead of stating all  that theorems we did for sequences, except now for limits of functions, I'm just going to
kind of quickly say you get the same thing.  to convergence of sequences, we have analogous analogous theorems for, and let me state it this way,  or limits of functions now, and for example, you have a squeeze theorem, namely if I have, so just talking this out, if I have three functions, say f is less than or equal to g is less than or equal to
h, and f of x and this converges to L, h of x  x converges to L, then g of x converges to L. That's what I mean by an analogous statement.  that have limits as x goes to c, then f plus g will have a limit as x goes to c, and that the limit of the sum is the sum of the limit, same thing with the product, and the
the same thing with the quotient, assuming the limit on the bottom is non-zero.  a theorem about the absolute value and limits, namely if f of x converges to L as x goes to c, then the absolute value of
f of x converges to the absolute value of L as x goes to c. So you have all of these analogous statements or theorems that are analogous to the statements from what we did for sequences, but now for limits of functions as x goes to c.  you can see this in the textbook, maybe the proof of some of them I'll
give as exercises. Now, let's separate the notion of a limit of a function from that of a sequence just a little bit. So unlike when we talk about limits of sequences, here we're letting a point x  or get close to a point c, but there's two ways you can get close to c on the real number line, it can converge to c from the left, or it can converge to c from the right, and this leads to the notion of left and right limits of a function,  functions. So start the definition here, and we'll go to the next board.  is a cluster point of minus infinity, 0 intersect c intersect S. So what I'm defining now is a notion of a function converging to something as x goes to c from the left. That's why I'm looking at only
S intersect minus infinity to c, so I'm only looking to the left of c.  We say, f of x converges to L as x converges to c from the left by putting a minus sign up here, if, as a summary definition as that of a limit, but now we only look at
x  getting close to c from the left. If for all epsilon positive, there
exists a delta positive positive such that for all x in S satisfying c minus delta is less than x is less than c. So it's close to c, but to the left of c, we have that f of x minus L,  is less than epsilon. And in this case, we write the limit as x goes to c, for the minus sign up top, f of x equals L.  or taking a limit of a function as x goes to c from the right, if c is cluster point of c infinity, c
come infinity intersects, so I shouldn't say if, suppose c is a cluster point  now just taking S that's to the right of c, and we say that f of x converges to L as x converges to c plus,
meaning as x converges to c from the right, if for all epsilon positive, there exists a delta positive,  for all x in S satisfying c is less than x is less than c plus delta. So now it's close to c, but to the
right of c, we have that f of x minus L is less than epsilon. And similarly, to the notation up there, we write limit as x goes to c plus  of f of x equals L. Now, just like we proved this theorem for limits, you can state and prove an analogous statement for one-sided limit.  sequence x sub n satisfying x sub n is less than c converging to c, we have f of xn converges to L. So these two just limit how f behaves near a point c if we're just looking to the left of c or to the right of c, but not at c.  think this is usually referred to as a heavy side function, so f of x equals 0 for x less than or
equal to 0 and 1 if x is bigger than or equal to 0. So graph is like that. And why do people care about this function?  certain sense, if you take the derivative of this function, you get what's called the
directional delta function, although that's not a function, that's a distribution, but that's why this function has a name attached to it, because if you take a derivative, you get something somewhat special.  if I look at this function for x close to 0 from the left, f is just 0. So, in fact, since I'm only looking at x to the left of 0 in this limit, this is just
plugging in x less than 0 so I get 0, and that's just 0  0, and if I look at this function from the right of 0, then f of x is just 1, it's just 1 identically, and so I get, and it's, again, so although I haven't shown that one-sided limits of
one-sided limits of constant's equal to constant, I think that should be something  you can easily believe or write out yourself. So for this function, we see that it does have two-sided limits, except those limits
don't equal each other, and they certainly don't equal, so this one does equal f of 0, but I could have made f of 0 to be 1 1 1, and then this still would have n0, and not equal to the function evaluated at the point.  point that for limits, just limits, it does not matter what the function is doing at the point. limit only cares about how a function behaves near a point, one-sided limit,
argument that by saying we're only going to care about the function near the point and to the left limit and to the right for the right limit.  simply because we're coming getting close to c from the right and from the left.  let S be a subset of R, f be a function from S to R, and suppose that c is cluster point of both sets minus infinity
to c intersect S, and c infinity intersect S. That way, I can talk about the left and right limits  or at c. Then, so first off, if c is a cluster point of any one of these sets, it's going to be a cluster point of the set S, so we can
actually look at the limit. So then the limit as x goes to c of f of x exists, n equals L, if and only if the limit  as x goes to c from the left of f of x equals the limit as x goes to c from the right of f of x equals L. So this kind of looks like the theorem we proved about limsup and liminf, but they don't have any connection.  So, so kind of what if you want to make some sort of connection between the way this theorem
looks and the statement of the theorem for liminf and limsup, so this is saying that limit of a function equals L, if we approach from the left or right, the function f approaches L. And for the liminf guy that we did for sequences, you could take that as saying that the limit of a  sequence equals L, if and only if following the sequence from below that approaches L and following the
sequence from above, that also approaches L. So there's two directions there just as there's two directions here, but not really.  this theorem, it's not difficult, it follows
almost immediately from the definitions.  and should assuming this and proving this should be pretty clear. If I have this, this means that if I want to be close to L, I just need to be close to c. And therefore, it doesn't matter if I'm close to c from the left or right, I'll be close to L.  the close to be close to L. So really there's not a lot of trickiness in the proof is just
writing these things out, and so I'm just going to write out one direction and leave the other direction to you.  that equals the right limit equals L. And now we want to show that the limit as x goes to c of f of x equals L. Now, we want to show limit as x goes to c of f of x equals L. So let's go back to the definition, let epsilon be positive, we want to be
be able to find a delta  so that f of x is within epsilon to L, if x is within delta to c, and what's the point here c? And here's L, so this is the picture that goes along with this, assuming these two limits equal L, I know that if there exists a delta 1, so that if  time in this interval, then, and here's L plus epsilon, L minus epsilon, then if I'm within delta 1 to c and to the left, then f will be close  to L in that interval. And then since the limit as x goes to c from the right equals L, there exists some delta 2 so that if I'm in this
interval, then I'll be, again, close to L. But this means that if I choose the smaller of these two, and I look at the whole interval, then f will be close to L on the whole interval, and that's it.  since limit as x goes to c minus f of x equals L, this implies there exists delta 1 positive such that if x minus c is less than delta 1, then I get that f of x  if c minus delta 1 is less than x is less than delta c, this implies that f of x minus L is less than epsilon, and
similarly for the right limit, since the limit as x goes to c plus of f of x equals L, this implies by the definition there exists a delta 2 positive,  that if c is less than x is less than c plus delta 2, then I get f of x minus L is less than epsilon. Now, choose delta to be the minimum of delta 1 delta 2.  show that this delta works. So now we're going to show this delta works.  either x is in c minus delta, so if we take something close within delta to c and delta is the minimum of these two
distance, then for the sake of this picture, let's say delta 1 equals delta 2, so now I'm looking at this interval, then two cases either x is in  c minus delta c, which is a subset of c minus delta 1, c, since delta is the minimum of those two
of those two delta, which implies by the first inequality here for delta 1 or x is in c plus delta, which is a subset  c c plus delta 2, which by our choice of delta 2 gives us that. Thus, we've shown that if x minus c is less than delta, then f of x minus L is less than
epsilon, that's the end of the proof.  I've said this over and over, and over again, limits of functions don't care about what the function is doing at the point,
carrows about what the function is doing near the point. Now, we're going to discuss the notion of continuity, which connects the limit of a function at a point  so it connects how a function behaves near a point to the function
evaluated at the point. And so I even write this down, how a function behaves near a point  compared to so near at point, and you'll see, when I write down the definition, basically, what's kind of staring you in the
face is that the definition  of continuity is that the limit as x goes to c of f of x equals f of c. So we had these examples where the limit, I think already erased it, where the limit exists, but does not equal f of c. And here, for continuity, the notion of continuity is that the limit as x goes to c of f of x actually equals the
function evaluated at that point.  following definition, let S be a subset of R and c an element of S, and say f is continuous at c if for all epsilon positive,  for all x and S satisfying x minus c is less than delta. So in particular, look, I can now, for example, x equals c, we'll satisfy this inequality. I don't have the 0 is less than that. So for all x and S, which are close to c within delta, I have that f of x will be  with an epsilon of f of c, so in this case, so just a little f is continuous at every point on its domain that we're
considering, we just say f is continuous.  So for a function to be continuous at a point near by x, x being  near c should mean that f of x should be near f of c. And we'll go through, let's go through some examples, remember, whenever you get a definition, you should look for examples, and then potentially negate it, will negate this definition in just a second to show that a
function I wrote down a minute ago  not continuous. So the f-ine function, f of x equals a times x plus b, so S is R, so x is a real number, is a continuous
function, meaning  is continuous at every real number c. So let's prove this. Let c be an element of R, we want to show f is
continuous at c. So we have to go through the definition of epsilon b positive, choose delta to be epsilon over 1 plus absolute value of a.  last time in the previous lecture, I gave the intuition on why you would choose this
delta based on the function and epsilon. I get a computation here, I'm just going to choose delta this way, and you'll see that it works. So now we have to show this delta works. If x minus c is less than delta, we should be able to now show that f of x minus f of c is less than epsilon,  this is equal to a, x plus b minus ac plus b, so this is equal to a times x minus c, which equals
absolute value of a times the absolute value of x minus c, this is less than delta, absolute value of x minus c is less than delta, times a, which equals absolute value of a over 1 plus the absolute value of a times epsilon,  which is less than epsilon, because a number over 1 plus that number is
always less than 1. Maybe you were wondering why did I just choose delta to be epsilon over the absolute value of a, this is just a smidgen of sophistication that what happens if the absolute value of a is equal to 0, then we would have divided by 0.  OK, so this guy is continuous at every c, so this
function is continuous. So I have about a function that's not continuous at a point  make sure this is the next topic.  2 if x not equal to 0, so that's the function, f is not continuous at 0.  is let's negate the definition of continuity, so the negation of continuity is, so f is not continuous at c if, so the forals become there exists, and there exists,
become for all, so if there exists some bad epsilon  so that for all delta positive, there exists an x such that x minus c is less than delta, and we do not have the second inequality, f of x minus f of c  bigger than or equal to this bad epsilon. Now, for this guy, it's pretty
clear which x to choose. So let's think this out for a minute. There should be some bad epsilon 0 so that if I take any small interval around 0, I can find a point in this interval so that f of x minus  f of c is going to be bigger than or equal to epsilon
0. Now, here, f of c is f of 0, which is 1. Now, what would be the bad epsilon so that f of 1 is greater than distance 1 or greater than distance epsilon 0 to f of x for some x in this interval?  get into f, I'm going to get 2, and that's with greater than or equal to
distance 1 to f of 0. So epsilon 0, I will choose to be 1. Now we want to prove that f, this function here, is not continuous at 0. So I'll tell you what the bad epsilon is, choose epsilon 0 equals 1.  So now we have to show this bad epsilon, epsilon 0 is, indeed, bad, that delta be positive. We have to now find a number in this interval so that f of x minus f of c, f of 0, is bigger than or equal to 1. And like I said a minute ago, if you take
x in this interval other than 0 and stick it into f, I get 2, which is distance 1 to f of 0.  x be delta over 2, say. Then x minus 0 is less than delta, it's actually equal to delta over 2, and f of x minus f of 0, this is equal to 2 minus 1, which is bigger than or
or equal to epsilon 0.  So this function is not continuous, and so next time, and I'll just leave this question here, which we'll address in the next lecture, but it's a simple question. So first off, if you look at this function, it shouldn't be too hard to
convent yourself, so you're also told in your child that a function  is continuous if you can draw the graph and not
lift up the pencil, which I better not see on the exam if I ask you about continuity, but anyways, for the sake of this conversation, let's take that as the intuition.  the value of the function at minus 1 is 2, so the function is getting close to the value of the
function at minus 1, and the same for if I'm looking at c equals 1. So you should be able to convince yourself that this function is continuous at every point other than at the origin 0. So a natural question to ask is let f be a function, let's say, defined on the whole real number  sign does there exist a point in R such that f is continuous at this point c?  make an arbitrary function, it doesn't have to have a point where it's continuous. And next time we'll see that that answer is no, we'll give an example that's, I think due to Dirichlet because it's named after him, but naming doesn't necessarily
mean anything in math, green is named after green, but it didn't prove it.  that's kind of analogous to this first statement we had for
limits, and we'll do that next time.